{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from collections import namedtuple\n",
    "import functools\n",
    "import csv\n",
    "import SimpleITK as sitk\n",
    "from util import XyzTuple, xyz2irc\n",
    "from util import enumerateWithEstimate\n",
    "from logconf import logging\n",
    "\n",
    "from disk import getCache\n",
    "from desets import LunaDataset\n",
    "import torch\n",
    "import torch.cuda\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "# log.setLevel(logging.WARN)\n",
    "log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 13:42:03,110 INFO     pid:32278 desets:288:__init__ <desets.LunaDataset object at 0x7905018d8650>: 56938 training samples, 56816 neg, 122 pos, unbalanced ratio\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_workers = 0\n",
    "\n",
    "prep_dl = DataLoader(\n",
    "    LunaDataset(sortby_str=\"series_uid\"),\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 13:42:05,440 WARNING  pid:32278 util:225:enumerateWithEstimate Stuffing cache ----/445, starting\n",
      "2024-10-29 13:42:05,628 INFO     pid:32278 util:245:enumerateWithEstimate Stuffing cache    4/445, done at 2024-10-29 13:42:22, 0:00:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-29 13:42:05.440726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 13:42:06,060 INFO     pid:32278 util:245:enumerateWithEstimate Stuffing cache   16/445, done at 2024-10-29 13:42:21, 0:00:16\n",
      "2024-10-29 13:42:07,698 INFO     pid:32278 util:245:enumerateWithEstimate Stuffing cache   64/445, done at 2024-10-29 13:42:20, 0:00:15\n",
      "2024-10-29 13:42:14,409 INFO     pid:32278 util:245:enumerateWithEstimate Stuffing cache  256/445, done at 2024-10-29 13:42:20, 0:00:15\n",
      "2024-10-29 13:42:20,922 WARNING  pid:32278 util:260:enumerateWithEstimate Stuffing cache ----/445, done at 2024-10-29 13:42:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-29 13:42:20.922786\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "batch_iter = enumerateWithEstimate(\n",
    "    prep_dl,\n",
    "    \"Stuffing cache\",\n",
    "    start_ndx=prep_dl.num_workers,\n",
    ")\n",
    "for _ in batch_iter:\n",
    "    pass\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, Adam\n",
    "from model import LunaModel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "# log.setLevel(logging.WARN)\n",
    "log.setLevel(logging.INFO)\n",
    "\n",
    "METRICS_LABEL_NDX = 0\n",
    "METRICS_PRED_NDX = 1\n",
    "METRICS_LOSS_NDX = 2\n",
    "METRICS_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 13:42:57,432 INFO     pid:32278 desets:288:__init__ <desets.LunaDataset object at 0x7904ce201810>: 5694 validation samples, 5681 neg, 13 pos, unbalanced ratio\n"
     ]
    }
   ],
   "source": [
    "def initValDl():\n",
    "    val_ds = LunaDataset(\n",
    "        val_stride=10,\n",
    "        isValSet_bool=True,\n",
    "    )\n",
    "    batch_size = 128\n",
    "\n",
    "    val_dl = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=device,\n",
    "    )\n",
    "\n",
    "    return val_dl\n",
    "\n",
    "\n",
    "val_dl = initValDl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 13:42:59,392 INFO     pid:32278 desets:288:__init__ <desets.LunaDataset object at 0x7904c8365f10>: 51244 training samples, 51135 neg, 109 pos, 1:1 ratio\n"
     ]
    }
   ],
   "source": [
    "augmentation_dict = {}\n",
    "\n",
    "augmentation_dict[\"flip\"] = True\n",
    "\n",
    "augmentation_dict[\"offset\"] = 0.1\n",
    "\n",
    "augmentation_dict[\"scale\"] = 0.2\n",
    "\n",
    "augmentation_dict[\"rotate\"] = True\n",
    "\n",
    "augmentation_dict[\"noise\"] = 25.0\n",
    "\n",
    "\n",
    "def initTrainDl():\n",
    "    train_ds = LunaDataset(\n",
    "        val_stride=10,\n",
    "        isValSet_bool=False,\n",
    "        ratio_int=1,\n",
    "        augmentation_dict=augmentation_dict,\n",
    "    )\n",
    "\n",
    "    batch_size = 128\n",
    "\n",
    "    train_dl = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=device,\n",
    "    )\n",
    "\n",
    "    return train_dl\n",
    "\n",
    "\n",
    "train_dl = initTrainDl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 13:43:05,688 INFO     pid:32278 __main__:004:initModel Using CUDA; 1 devices.\n"
     ]
    }
   ],
   "source": [
    "def initModel():\n",
    "    model = LunaModel()\n",
    "    if device:\n",
    "        log.info(\"Using CUDA; {} devices.\".format(torch.cuda.device_count()))\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "        model = model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = initModel()\n",
    "# writer = SummaryWriter(\"./log_seq\")\n",
    "# writer.add_graph(model, input)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initOptimizer():\n",
    "    return SGD(model.parameters(), lr=0.001, momentum=0.99)\n",
    "    # return Adam(self.model.parameters())\n",
    "\n",
    "\n",
    "optimizer = initOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeBatchLoss(batch_ndx, batch_tup, batch_size, metrics_g):\n",
    "    input_t, label_t, _series_list, _center_list = batch_tup\n",
    "\n",
    "    input_g = input_t.to(device, non_blocking=True)\n",
    "    label_g = label_t.to(device, non_blocking=True)\n",
    "\n",
    "    logits_g, probability_g = model(input_g)\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    loss_g = loss_func(\n",
    "        logits_g,\n",
    "        label_g[:, 1],\n",
    "    )\n",
    "    start_ndx = batch_ndx * batch_size\n",
    "    end_ndx = start_ndx + label_t.size(0)\n",
    "\n",
    "    metrics_g[METRICS_LABEL_NDX, start_ndx:end_ndx] = label_g[:, 1].detach()\n",
    "    metrics_g[METRICS_PRED_NDX, start_ndx:end_ndx] = probability_g[:, 1].detach()\n",
    "    metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = loss_g.detach()\n",
    "\n",
    "    return loss_g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doTraining(epoch_ndx, train_dl, totalTrainingSamples_count=0):\n",
    "    model.train()\n",
    "    train_dl.dataset.shuffleSamples()\n",
    "    trnMetrics_g = torch.zeros(\n",
    "        METRICS_SIZE,\n",
    "        len(train_dl.dataset),\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    batch_iter = enumerateWithEstimate(\n",
    "        train_dl,\n",
    "        \"E{} Training\".format(epoch_ndx),\n",
    "        start_ndx=train_dl.num_workers,\n",
    "    )\n",
    "    for batch_ndx, batch_tup in batch_iter:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_var = computeBatchLoss(\n",
    "            batch_ndx, batch_tup, train_dl.batch_size, trnMetrics_g\n",
    "        )\n",
    "\n",
    "        loss_var.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    totalTrainingSamples_count += len(train_dl.dataset)\n",
    "\n",
    "    return trnMetrics_g.to(\"cpu\")\n",
    "\n",
    "\n",
    "def doValidation(epoch_ndx, val_dl):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valMetrics_g = torch.zeros(\n",
    "            METRICS_SIZE,\n",
    "            len(val_dl.dataset),\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        batch_iter = enumerateWithEstimate(\n",
    "            val_dl,\n",
    "            \"E{} Validation \".format(epoch_ndx),\n",
    "            start_ndx=val_dl.num_workers,\n",
    "        )\n",
    "        for batch_ndx, batch_tup in batch_iter:\n",
    "            computeBatchLoss(batch_ndx, batch_tup, val_dl.batch_size, valMetrics_g)\n",
    "\n",
    "    return valMetrics_g.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logMetrics(\n",
    "    epoch_ndx,\n",
    "    mode_str,\n",
    "    metrics_t,\n",
    "    classificationThreshold=0.5,\n",
    "):\n",
    "\n",
    "    negLabel_mask = metrics_t[METRICS_LABEL_NDX] <= classificationThreshold\n",
    "    negPred_mask = metrics_t[METRICS_PRED_NDX] <= classificationThreshold\n",
    "\n",
    "    posLabel_mask = ~negLabel_mask\n",
    "    posPred_mask = ~negPred_mask\n",
    "\n",
    "    neg_count = int(negLabel_mask.sum())\n",
    "    pos_count = int(posLabel_mask.sum())\n",
    "\n",
    "    trueNeg_count = neg_correct = int((negLabel_mask & negPred_mask).sum())\n",
    "    truePos_count = pos_correct = int((posLabel_mask & posPred_mask).sum())\n",
    "\n",
    "    falsePos_count = neg_count - neg_correct\n",
    "    falseNeg_count = pos_count - pos_correct\n",
    "\n",
    "    metrics_dict = {}\n",
    "    metrics_dict[\"loss/all\"] = metrics_t[METRICS_LOSS_NDX].mean()\n",
    "    metrics_dict[\"loss/neg\"] = metrics_t[METRICS_LOSS_NDX, negLabel_mask].mean()\n",
    "    metrics_dict[\"loss/pos\"] = metrics_t[METRICS_LOSS_NDX, posLabel_mask].mean()\n",
    "\n",
    "    metrics_dict[\"correct/all\"] = (\n",
    "        (pos_correct + neg_correct) / np.float32(metrics_t.shape[1]) * 100\n",
    "    )\n",
    "    metrics_dict[\"correct/neg\"] = neg_correct / np.float32(neg_count) * 100\n",
    "    metrics_dict[\"correct/pos\"] = pos_correct / np.float32(pos_count) * 100\n",
    "\n",
    "    precision = metrics_dict[\"pr/precision\"] = truePos_count / np.float32(\n",
    "        truePos_count + falsePos_count\n",
    "    )\n",
    "    recall = metrics_dict[\"pr/recall\"] = truePos_count / np.float32(\n",
    "        truePos_count + falseNeg_count\n",
    "    )\n",
    "\n",
    "    metrics_dict[\"pr/f1_score\"] = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    log.info(\n",
    "        (\n",
    "            \"E{} {:8} {loss/all:.4f} loss, \"\n",
    "            + \"{correct/all:-5.1f}% correct, \"\n",
    "            + \"{pr/precision:.4f} precision, \"\n",
    "            + \"{pr/recall:.4f} recall, \"\n",
    "            + \"{pr/f1_score:.4f} f1 score\"\n",
    "        ).format(\n",
    "            epoch_ndx,\n",
    "            mode_str,\n",
    "            **metrics_dict,\n",
    "        )\n",
    "    )\n",
    "    log.info(\n",
    "        (\n",
    "            \"E{} {:8} {loss/neg:.4f} loss, \"\n",
    "            + \"{correct/neg:-5.1f}% correct ({neg_correct:} of {neg_count:})\"\n",
    "        ).format(\n",
    "            epoch_ndx,\n",
    "            mode_str + \"_neg\",\n",
    "            neg_correct=neg_correct,\n",
    "            neg_count=neg_count,\n",
    "            **metrics_dict,\n",
    "        )\n",
    "    )\n",
    "    log.info(\n",
    "        (\n",
    "            \"E{} {:8} {loss/pos:.4f} loss, \"\n",
    "            + \"{correct/pos:-5.1f}% correct ({pos_correct:} of {pos_count:})\"\n",
    "        ).format(\n",
    "            epoch_ndx,\n",
    "            mode_str + \"_pos\",\n",
    "            pos_correct=pos_correct,\n",
    "            pos_count=pos_count,\n",
    "            **metrics_dict,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Load traning to tensorBoard\n",
    "    # writer = SummaryWriter(\"./logs\")\n",
    "    # for key, value in metrics_dict.items():\n",
    "    #     writer.add_scalar(key, value, epoch_ndx)\n",
    "    # writer.close()\n",
    "    # tensorboard --logdir=logs/fit\n",
    "\n",
    "    # for key, value in metrics_dict.items():\n",
    "    #     print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 13:43:25,557 INFO     pid:32278 __main__:004:<module> Epoch 1 of 1, 1563/45 batches of size 128*cuda\n",
      "2024-10-29 13:43:25,584 WARNING  pid:32278 util:225:enumerateWithEstimate E1 Training ----/1563, starting\n",
      "2024-10-29 13:43:26,651 INFO     pid:32278 util:245:enumerateWithEstimate E1 Training    4/1563, done at 2024-10-29 13:48:58, 0:05:33\n",
      "2024-10-29 13:43:30,017 INFO     pid:32278 util:245:enumerateWithEstimate E1 Training   16/1563, done at 2024-10-29 13:50:13, 0:06:47\n",
      "2024-10-29 13:43:48,000 INFO     pid:32278 util:245:enumerateWithEstimate E1 Training   64/1563, done at 2024-10-29 13:52:24, 0:08:58\n",
      "2024-10-29 13:45:01,051 INFO     pid:32278 util:245:enumerateWithEstimate E1 Training  256/1563, done at 2024-10-29 13:53:06, 0:09:40\n",
      "2024-10-29 13:50:01,448 INFO     pid:32278 util:245:enumerateWithEstimate E1 Training 1024/1563, done at 2024-10-29 13:53:29, 0:10:03\n",
      "2024-10-29 13:53:37,773 WARNING  pid:32278 util:260:enumerateWithEstimate E1 Training ----/1563, done at 2024-10-29 13:53:37\n",
      "2024-10-29 13:53:39,910 INFO     pid:32278 __main__:043:logMetrics E1 trn      0.0611 loss,  97.0% correct, 0.9697 precision, 0.9704 recall, 0.9701 f1 score\n",
      "2024-10-29 13:53:39,910 INFO     pid:32278 __main__:056:logMetrics E1 trn_neg  0.0699 loss,  97.0% correct (96971 of 100000)\n",
      "2024-10-29 13:53:39,910 INFO     pid:32278 __main__:068:logMetrics E1 trn_pos  0.0524 loss,  97.0% correct (97040 of 100000)\n",
      "2024-10-29 13:53:39,911 WARNING  pid:32278 util:225:enumerateWithEstimate E1 Validation  ----/45, starting\n",
      "2024-10-29 13:53:40,073 INFO     pid:32278 util:245:enumerateWithEstimate E1 Validation     4/45, done at 2024-10-29 13:53:41, 0:00:01\n",
      "2024-10-29 13:53:40,198 INFO     pid:32278 util:245:enumerateWithEstimate E1 Validation     8/45, done at 2024-10-29 13:53:41, 0:00:01\n",
      "2024-10-29 13:53:40,535 INFO     pid:32278 util:245:enumerateWithEstimate E1 Validation    16/45, done at 2024-10-29 13:53:41, 0:00:01\n",
      "2024-10-29 13:53:41,545 INFO     pid:32278 util:245:enumerateWithEstimate E1 Validation    32/45, done at 2024-10-29 13:53:42, 0:00:02\n",
      "2024-10-29 13:53:43,031 WARNING  pid:32278 util:260:enumerateWithEstimate E1 Validation  ----/45, done at 2024-10-29 13:53:43\n",
      "2024-10-29 13:53:45,442 INFO     pid:32278 __main__:043:logMetrics E1 val      0.0423 loss,  99.7% correct, 0.2500 precision, 0.2308 recall, 0.2400 f1 score\n",
      "2024-10-29 13:53:45,442 INFO     pid:32278 __main__:056:logMetrics E1 val_neg  0.0070 loss,  99.8% correct (5672 of 5681)\n",
      "2024-10-29 13:53:45,443 INFO     pid:32278 __main__:068:logMetrics E1 val_pos  15.4671 loss,  23.1% correct (3 of 13)\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "for epoch_ndx in range(1, epochs + 1):\n",
    "    log.info(\n",
    "        \"Epoch {} of {}, {}/{} batches of size {}*{}\".format(\n",
    "            epoch_ndx,\n",
    "            epochs,\n",
    "            len(train_dl),\n",
    "            len(val_dl),\n",
    "            batch_size,\n",
    "            torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    trnMetrics_t = doTraining(epoch_ndx, train_dl)\n",
    "    logMetrics(epoch_ndx, \"trn\", trnMetrics_t)\n",
    "\n",
    "    valMetrics_t = doValidation(epoch_ndx, val_dl)\n",
    "    logMetrics(epoch_ndx, \"val\", valMetrics_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
