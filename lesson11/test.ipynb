{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from collections import namedtuple\n",
    "import functools\n",
    "import csv\n",
    "import SimpleITK as sitk\n",
    "from util import XyzTuple, xyz2irc\n",
    "from util import enumerateWithEstimate\n",
    "from logconf import logging\n",
    "\n",
    "from disk import getCache\n",
    "from desets import LunaDataset\n",
    "import torch\n",
    "import torch.cuda\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "# log.setLevel(logging.WARN)\n",
    "log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 16:47:44,625 INFO     pid:33738 desets:202:__init__ <desets.LunaDataset object at 0x7b622264fc90>: 56938 training samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_workers = 0\n",
    "\n",
    "prep_dl = DataLoader(\n",
    "    LunaDataset(\n",
    "        sortby_str=\"series_uid\",\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_dl.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 16:24:08,872 WARNING  pid:33738 util:225:enumerateWithEstimate Stuffing cache ----/445, starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-28 16:24:08.872623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 16:24:09,075 INFO     pid:33738 util:245:enumerateWithEstimate Stuffing cache    4/445, done at 2024-10-28 16:24:26, 0:00:17\n",
      "2024-10-28 16:24:09,539 INFO     pid:33738 util:245:enumerateWithEstimate Stuffing cache   16/445, done at 2024-10-28 16:24:26, 0:00:17\n",
      "2024-10-28 16:24:11,354 INFO     pid:33738 util:245:enumerateWithEstimate Stuffing cache   64/445, done at 2024-10-28 16:24:25, 0:00:16\n",
      "2024-10-28 16:24:18,624 INFO     pid:33738 util:245:enumerateWithEstimate Stuffing cache  256/445, done at 2024-10-28 16:24:25, 0:00:16\n",
      "2024-10-28 16:24:25,673 WARNING  pid:33738 util:260:enumerateWithEstimate Stuffing cache ----/445, done at 2024-10-28 16:24:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-28 16:24:25.673950\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "batch_iter = enumerateWithEstimate(\n",
    "    prep_dl,\n",
    "    \"Stuffing cache\",\n",
    "    start_ndx=prep_dl.num_workers,\n",
    ")\n",
    "for _ in batch_iter:\n",
    "    pass\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, Adam\n",
    "from model import LunaModel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "# log.setLevel(logging.WARN)\n",
    "log.setLevel(logging.INFO)\n",
    "\n",
    "METRICS_LABEL_NDX = 0\n",
    "METRICS_PRED_NDX = 1\n",
    "METRICS_LOSS_NDX = 2\n",
    "METRICS_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 16:44:41,375 INFO     pid:33738 desets:202:__init__ <desets.LunaDataset object at 0x7b62227d9ed0>: 5694 validation samples\n"
     ]
    }
   ],
   "source": [
    "def initValDl():\n",
    "    val_ds = LunaDataset(\n",
    "        val_stride=10,\n",
    "        isValSet_bool=True,\n",
    "    )\n",
    "    batch_size = 128\n",
    "\n",
    "    val_dl = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=device,\n",
    "    )\n",
    "\n",
    "    return val_dl\n",
    "\n",
    "\n",
    "val_dl = initValDl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 16:49:22,065 INFO     pid:33738 desets:202:__init__ <desets.LunaDataset object at 0x7b621b1a7390>: 51244 training samples\n"
     ]
    }
   ],
   "source": [
    "def initTrainDl():\n",
    "    train_ds = LunaDataset(\n",
    "        val_stride=10,\n",
    "        isValSet_bool=False,\n",
    "    )\n",
    "\n",
    "    batch_size = 128\n",
    "\n",
    "    train_dl = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=device,\n",
    "    )\n",
    "\n",
    "    return train_dl\n",
    "\n",
    "\n",
    "train_dl = initTrainDl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 16:42:14,713 INFO     pid:33738 __main__:004:initModel Using CUDA; 1 devices.\n"
     ]
    }
   ],
   "source": [
    "def initModel():\n",
    "    model = LunaModel()\n",
    "    if device:\n",
    "        log.info(\"Using CUDA; {} devices.\".format(torch.cuda.device_count()))\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "        model = model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = initModel()\n",
    "# writer = SummaryWriter(\"./log_seq\")\n",
    "# writer.add_graph(model, input)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initOptimizer():\n",
    "    return SGD(model.parameters(), lr=0.001, momentum=0.99)\n",
    "    # return Adam(self.model.parameters())\n",
    "\n",
    "\n",
    "optimizer = initOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeBatchLoss(batch_ndx, batch_tup, batch_size, metrics_g):\n",
    "    input_t, label_t, _series_list, _center_list = batch_tup\n",
    "\n",
    "    input_g = input_t.to(device, non_blocking=True)\n",
    "    label_g = label_t.to(device, non_blocking=True)\n",
    "\n",
    "    logits_g, probability_g = model(input_g)\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    loss_g = loss_func(\n",
    "        logits_g,\n",
    "        label_g[:, 1],\n",
    "    )\n",
    "    start_ndx = batch_ndx * batch_size\n",
    "    end_ndx = start_ndx + label_t.size(0)\n",
    "\n",
    "    metrics_g[METRICS_LABEL_NDX, start_ndx:end_ndx] = label_g[:, 1].detach()\n",
    "    metrics_g[METRICS_PRED_NDX, start_ndx:end_ndx] = probability_g[:, 1].detach()\n",
    "    metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = loss_g.detach()\n",
    "\n",
    "    return loss_g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doTraining(epoch_ndx, train_dl, totalTrainingSamples_count=0):\n",
    "    model.train()\n",
    "    trnMetrics_g = torch.zeros(\n",
    "        METRICS_SIZE,\n",
    "        len(train_dl.dataset),\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    batch_iter = enumerateWithEstimate(\n",
    "        train_dl,\n",
    "        \"E{} Training\".format(epoch_ndx),\n",
    "        start_ndx=train_dl.num_workers,\n",
    "    )\n",
    "    for batch_ndx, batch_tup in batch_iter:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_var = computeBatchLoss(\n",
    "            batch_ndx, batch_tup, train_dl.batch_size, trnMetrics_g\n",
    "        )\n",
    "\n",
    "        loss_var.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    totalTrainingSamples_count += len(train_dl.dataset)\n",
    "\n",
    "    return trnMetrics_g.to(\"cpu\")\n",
    "\n",
    "\n",
    "def doValidation(epoch_ndx, val_dl):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valMetrics_g = torch.zeros(\n",
    "            METRICS_SIZE,\n",
    "            len(val_dl.dataset),\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        batch_iter = enumerateWithEstimate(\n",
    "            val_dl,\n",
    "            \"E{} Validation \".format(epoch_ndx),\n",
    "            start_ndx=val_dl.num_workers,\n",
    "        )\n",
    "        for batch_ndx, batch_tup in batch_iter:\n",
    "            computeBatchLoss(batch_ndx, batch_tup, val_dl.batch_size, valMetrics_g)\n",
    "\n",
    "    return valMetrics_g.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logMetrics(\n",
    "    epoch_ndx,\n",
    "    mode_str,\n",
    "    metrics_t,\n",
    "    classificationThreshold=0.5,\n",
    "):\n",
    "\n",
    "    negLabel_mask = metrics_t[METRICS_LABEL_NDX] <= classificationThreshold\n",
    "    negPred_mask = metrics_t[METRICS_PRED_NDX] <= classificationThreshold\n",
    "\n",
    "    posLabel_mask = ~negLabel_mask\n",
    "    posPred_mask = ~negPred_mask\n",
    "\n",
    "    neg_count = int(negLabel_mask.sum())\n",
    "    pos_count = int(posLabel_mask.sum())\n",
    "\n",
    "    neg_correct = int((negLabel_mask & negPred_mask).sum())\n",
    "    pos_correct = int((posLabel_mask & posPred_mask).sum())\n",
    "\n",
    "    metrics_dict = {}\n",
    "    metrics_dict[\"loss/all\"] = metrics_t[METRICS_LOSS_NDX].mean()\n",
    "    metrics_dict[\"loss/neg\"] = metrics_t[METRICS_LOSS_NDX, negLabel_mask].mean()\n",
    "    metrics_dict[\"loss/pos\"] = metrics_t[METRICS_LOSS_NDX, posLabel_mask].mean()\n",
    "\n",
    "    metrics_dict[\"correct/all\"] = (\n",
    "        (pos_correct + neg_correct) / np.float32(metrics_t.shape[1]) * 100\n",
    "    )\n",
    "    metrics_dict[\"correct/neg\"] = neg_correct / np.float32(neg_count) * 100\n",
    "    metrics_dict[\"correct/pos\"] = pos_correct / np.float32(pos_count) * 100\n",
    "\n",
    "    log.info(\n",
    "        (\"E{} {:8} {loss/all:.4f} loss, \" + \"{correct/all:-5.1f}% correct, \").format(\n",
    "            epoch_ndx,\n",
    "            mode_str,\n",
    "            **metrics_dict,\n",
    "        )\n",
    "    )\n",
    "    log.info(\n",
    "        (\n",
    "            \"E{} {:8} {loss/neg:.4f} loss, \"\n",
    "            + \"{correct/neg:-5.1f}% correct ({neg_correct:} of {neg_count:})\"\n",
    "        ).format(\n",
    "            epoch_ndx,\n",
    "            mode_str + \"_neg\",\n",
    "            neg_correct=neg_correct,\n",
    "            neg_count=neg_count,\n",
    "            **metrics_dict,\n",
    "        )\n",
    "    )\n",
    "    log.info(\n",
    "        (\n",
    "            \"E{} {:8} {loss/pos:.4f} loss, \"\n",
    "            + \"{correct/pos:-5.1f}% correct ({pos_correct:} of {pos_count:})\"\n",
    "        ).format(\n",
    "            epoch_ndx,\n",
    "            mode_str + \"_pos\",\n",
    "            pos_correct=pos_correct,\n",
    "            pos_count=pos_count,\n",
    "            **metrics_dict,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Load traning to tensorBoard\n",
    "    writer = SummaryWriter(\"./logs\")\n",
    "    for key, value in metrics_dict.items():\n",
    "        writer.add_scalar(key, value, epoch_ndx)\n",
    "    writer.close()\n",
    "    # tensorboard --logdir=logs/fit\n",
    "\n",
    "    # for key, value in metrics_dict.items():\n",
    "    #     print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 16:32:46,877 INFO     pid:33738 __main__:004:<module> Epoch 1 of 1, 401/45 batches of size 128*cuda\n",
      "2024-10-28 16:32:46,885 WARNING  pid:33738 util:225:enumerateWithEstimate E1 Training ----/401, starting\n",
      "2024-10-28 16:32:47,059 INFO     pid:33738 util:245:enumerateWithEstimate E1 Training    4/401, done at 2024-10-28 16:33:00, 0:00:13\n",
      "2024-10-28 16:32:51,041 INFO     pid:33738 util:245:enumerateWithEstimate E1 Training   16/401, done at 2024-10-28 16:34:24, 0:01:38\n",
      "2024-10-28 16:33:08,769 INFO     pid:33738 util:245:enumerateWithEstimate E1 Training   64/401, done at 2024-10-28 16:35:01, 0:02:15\n",
      "2024-10-28 16:34:20,981 INFO     pid:33738 util:245:enumerateWithEstimate E1 Training  256/401, done at 2024-10-28 16:35:13, 0:02:26\n",
      "2024-10-28 16:35:15,634 WARNING  pid:33738 util:260:enumerateWithEstimate E1 Training ----/401, done at 2024-10-28 16:35:15\n",
      "2024-10-28 16:35:17,563 INFO     pid:33738 __main__:031:logMetrics E1 trn      0.0158 loss,  99.8% correct, \n",
      "2024-10-28 16:35:17,564 INFO     pid:33738 __main__:038:logMetrics E1 trn_neg  0.0020 loss, 100.0% correct (51135 of 51135)\n",
      "2024-10-28 16:35:17,564 INFO     pid:33738 __main__:050:logMetrics E1 trn_pos  6.4921 loss,   0.0% correct (0 of 109)\n",
      "2024-10-28 16:35:17,565 WARNING  pid:33738 util:225:enumerateWithEstimate E1 Validation  ----/45, starting\n",
      "2024-10-28 16:35:17,707 INFO     pid:33738 util:245:enumerateWithEstimate E1 Validation     4/45, done at 2024-10-28 16:35:18, 0:00:01\n",
      "2024-10-28 16:35:17,821 INFO     pid:33738 util:245:enumerateWithEstimate E1 Validation     8/45, done at 2024-10-28 16:35:18, 0:00:01\n",
      "2024-10-28 16:35:18,050 INFO     pid:33738 util:245:enumerateWithEstimate E1 Validation    16/45, done at 2024-10-28 16:35:18, 0:00:01\n",
      "2024-10-28 16:35:19,085 INFO     pid:33738 util:245:enumerateWithEstimate E1 Validation    32/45, done at 2024-10-28 16:35:19, 0:00:02\n",
      "2024-10-28 16:35:20,469 WARNING  pid:33738 util:260:enumerateWithEstimate E1 Validation  ----/45, done at 2024-10-28 16:35:20\n",
      "2024-10-28 16:35:22,720 INFO     pid:33738 __main__:031:logMetrics E1 val      0.0168 loss,  99.8% correct, \n",
      "2024-10-28 16:35:22,720 INFO     pid:33738 __main__:038:logMetrics E1 val_neg  0.0045 loss, 100.0% correct (5681 of 5681)\n",
      "2024-10-28 16:35:22,721 INFO     pid:33738 __main__:050:logMetrics E1 val_pos  5.4083 loss,   0.0% correct (0 of 13)\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "for epoch_ndx in range(1, epochs + 1):\n",
    "    log.info(\n",
    "        \"Epoch {} of {}, {}/{} batches of size {}*{}\".format(\n",
    "            epoch_ndx,\n",
    "            epochs,\n",
    "            len(train_dl),\n",
    "            len(val_dl),\n",
    "            batch_size,\n",
    "            torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    trnMetrics_t = doTraining(epoch_ndx, train_dl)\n",
    "    logMetrics(epoch_ndx, \"trn\", trnMetrics_t)\n",
    "\n",
    "    valMetrics_t = doValidation(epoch_ndx, val_dl)\n",
    "    logMetrics(epoch_ndx, \"val\", valMetrics_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
