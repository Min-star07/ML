{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7c203caca270>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class_names = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "data_path = \"../lesson3/dataset\"\n",
    "# cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
    "# cifar10 = datasets.CIFAR10(data_path, train=False, download=True)\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616)),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = [\"airplane\", \"bird\"]\n",
    "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_out = 2\n",
    "model = nn.Sequential(nn.Linear(3072, 512), nn.Tanh(), nn.Linear(512, n_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "x = torch.tensor([[1.0, 2.0, 3.0], [3.0, 4.0, 5.0]])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_out = 2\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512), nn.Tanh(), nn.Linear(512, n_out), nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7c1f5f87e150>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img.view(-1): Flattens the tensor.\n",
    "unsqueeze(0): Adds a batch dimension (resulting in a shape like [1, N], where N is the total number of elements in the original tensor).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3072])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch = img.view(-1).unsqueeze(0)\n",
    "img_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch2 = img.unsqueeze(0)\n",
    "img_batch2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4784, 0.5216]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(img_batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, index = torch.max(out, dim=1)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.tensor(\n",
    "    [\n",
    "        [0.6, 0.4],\n",
    "        [0.9, 0.1],\n",
    "        [0.3, 0.7],\n",
    "        [0.2, 0.8],\n",
    "    ]\n",
    ")\n",
    "\n",
    "class_index = torch.tensor([0, 0, 1, 1]).unsqueeze(1)\n",
    "class_index\n",
    "truth = torch.zeros((4, 2))\n",
    "truth\n",
    "truth.scatter_(dim=1, index=class_index, value=1.0)\n",
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse(out):\n",
    "    return ((out - truth) ** 2).sum(dim=1).mean()\n",
    "    # y = (out - truth) ** 2\n",
    "    # print(y)\n",
    "\n",
    "\n",
    "mse(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6000],\n",
       "        [0.9000],\n",
       "        [0.7000],\n",
       "        [0.8000]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.gather(dim=1, index=class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3024])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def likelihood(out):\n",
    "    prod = 1.0\n",
    "    for x in out.gather(dim=1, index=class_index):\n",
    "\n",
    "        prod *= x\n",
    "\n",
    "    return prod\n",
    "\n",
    "\n",
    "likelihood(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1960])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def neg_log_likelihood(out):\n",
    "    return -likelihood(out).log()\n",
    "\n",
    "\n",
    "neg_log_likelihood(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6000, 0.4000],\n",
       "        [0.9000, 0.1000],\n",
       "        [0.3000, 0.7000],\n",
       "        [0.2000, 0.8000]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0750, 0.1500, 0.2500, 0.4750])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out0 = out.clone().detach()\n",
    "out0[0] = torch.tensor([0.9, 0.1])\n",
    "out2 = out.clone().detach()\n",
    "out2[0] = torch.tensor([0.4, 0.6])\n",
    "out3 = out.clone().detach()\n",
    "out3[0] = torch.tensor([0.1, 0.9])\n",
    "\n",
    "mse_comparison = torch.tensor([mse(o) for o in [out0, out, out2, out3]])\n",
    "mse_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9000, 0.1000],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.3000, 0.7000],\n",
      "        [0.2000, 0.8000]])\n",
      "tensor(0.0750)\n",
      "tensor([[0.6000, 0.4000],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.3000, 0.7000],\n",
      "        [0.2000, 0.8000]])\n",
      "tensor(0.1500)\n",
      "tensor([[0.4000, 0.6000],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.3000, 0.7000],\n",
      "        [0.2000, 0.8000]])\n",
      "tensor(0.2500)\n",
      "tensor([[0.1000, 0.9000],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.3000, 0.7000],\n",
      "        [0.2000, 0.8000]])\n",
      "tensor(0.4750)\n"
     ]
    }
   ],
   "source": [
    "for o in [out0, out, out2, out3]:\n",
    "    print(o)\n",
    "    mse(o)\n",
    "    print(mse(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-50.0000,   0.0000,  66.6667, 216.6667])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((mse_comparison / mse_comparison[1]) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7905, 1.1960, 1.6015, 2.9878])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll_comparison = torch.tensor([neg_log_likelihood(o) for o in [out0, out, out2, out3]])\n",
    "nll_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-33.9016,   0.0000,  33.9016, 149.8121])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((nll_comparison / nll_comparison[1]) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[0.0, 104.0]])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-104.,    0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[0.0, 104.0]])\n",
    "\n",
    "log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(log_softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5077, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512), nn.Tanh(), nn.Linear(512, 2), nn.LogSoftmax(dim=1)\n",
    ")\n",
    "loss = nn.NLLLoss()\n",
    "img, label = cifar2[0]\n",
    "\n",
    "out = model(img.view(-1).unsqueeze(0))\n",
    "\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, LOss : 2.808479\n",
      "Epoch : 1, LOss : 2.832569\n",
      "Epoch : 2, LOss : 5.176270\n",
      "Epoch : 3, LOss : 5.776686\n",
      "Epoch : 4, LOss : 3.877132\n",
      "Epoch : 5, LOss : 2.053756\n",
      "Epoch : 6, LOss : 9.040649\n",
      "Epoch : 7, LOss : 9.483339\n",
      "Epoch : 8, LOss : 14.036193\n",
      "Epoch : 9, LOss : 6.748063\n",
      "Epoch : 10, LOss : 10.453506\n",
      "Epoch : 11, LOss : 7.707525\n",
      "Epoch : 12, LOss : 11.678914\n",
      "Epoch : 13, LOss : 2.176284\n",
      "Epoch : 14, LOss : 11.310536\n",
      "Epoch : 15, LOss : 8.300934\n",
      "Epoch : 16, LOss : 9.714619\n",
      "Epoch : 17, LOss : 16.265474\n",
      "Epoch : 18, LOss : 15.884706\n",
      "Epoch : 19, LOss : 6.464939\n",
      "Epoch : 20, LOss : 6.790210\n",
      "Epoch : 21, LOss : 11.052434\n",
      "Epoch : 22, LOss : 10.355342\n",
      "Epoch : 23, LOss : 1.387925\n",
      "Epoch : 24, LOss : 7.006418\n",
      "Epoch : 25, LOss : 3.956246\n",
      "Epoch : 26, LOss : 3.005236\n",
      "Epoch : 27, LOss : 8.344983\n",
      "Epoch : 28, LOss : 5.165214\n",
      "Epoch : 29, LOss : 13.271230\n",
      "Epoch : 30, LOss : 9.225438\n",
      "Epoch : 31, LOss : 2.415284\n",
      "Epoch : 32, LOss : 11.242496\n",
      "Epoch : 33, LOss : 11.464164\n",
      "Epoch : 34, LOss : 3.139958\n",
      "Epoch : 35, LOss : 17.346771\n",
      "Epoch : 36, LOss : 11.193871\n",
      "Epoch : 37, LOss : 12.378817\n",
      "Epoch : 38, LOss : 6.514275\n",
      "Epoch : 39, LOss : 15.586023\n",
      "Epoch : 40, LOss : 0.056469\n",
      "Epoch : 41, LOss : 4.299170\n",
      "Epoch : 42, LOss : 1.542363\n",
      "Epoch : 43, LOss : 1.653413\n",
      "Epoch : 44, LOss : 9.200792\n",
      "Epoch : 45, LOss : 5.976705\n",
      "Epoch : 46, LOss : 10.888958\n",
      "Epoch : 47, LOss : 11.263831\n",
      "Epoch : 48, LOss : 11.075762\n",
      "Epoch : 49, LOss : 0.910399\n",
      "Epoch : 50, LOss : 6.889470\n",
      "Epoch : 51, LOss : 12.635478\n",
      "Epoch : 52, LOss : 9.053387\n",
      "Epoch : 53, LOss : 10.476379\n",
      "Epoch : 54, LOss : 7.031883\n",
      "Epoch : 55, LOss : 13.845960\n",
      "Epoch : 56, LOss : 14.754181\n",
      "Epoch : 57, LOss : 6.144845\n",
      "Epoch : 58, LOss : 7.048274\n",
      "Epoch : 59, LOss : 9.703763\n",
      "Epoch : 60, LOss : 7.857391\n",
      "Epoch : 61, LOss : 5.282369\n",
      "Epoch : 62, LOss : 10.974264\n",
      "Epoch : 63, LOss : 19.665131\n",
      "Epoch : 64, LOss : 0.075511\n",
      "Epoch : 65, LOss : 15.371458\n",
      "Epoch : 66, LOss : 2.212575\n",
      "Epoch : 67, LOss : 10.266663\n",
      "Epoch : 68, LOss : 7.891601\n",
      "Epoch : 69, LOss : 0.905052\n",
      "Epoch : 70, LOss : 4.395932\n",
      "Epoch : 71, LOss : 13.716824\n",
      "Epoch : 72, LOss : 12.611544\n",
      "Epoch : 73, LOss : 9.820255\n",
      "Epoch : 74, LOss : 15.474329\n",
      "Epoch : 75, LOss : 20.901955\n",
      "Epoch : 76, LOss : 24.449139\n",
      "Epoch : 77, LOss : 20.545246\n",
      "Epoch : 78, LOss : 14.103091\n",
      "Epoch : 79, LOss : 13.152252\n",
      "Epoch : 80, LOss : 16.410963\n",
      "Epoch : 81, LOss : 4.473562\n",
      "Epoch : 82, LOss : 11.227635\n",
      "Epoch : 83, LOss : 10.553666\n",
      "Epoch : 84, LOss : 11.815163\n",
      "Epoch : 85, LOss : 5.786355\n",
      "Epoch : 86, LOss : 1.151752\n",
      "Epoch : 87, LOss : 4.879501\n",
      "Epoch : 88, LOss : 11.749174\n",
      "Epoch : 89, LOss : 10.597261\n",
      "Epoch : 90, LOss : 10.691960\n",
      "Epoch : 91, LOss : 18.205006\n",
      "Epoch : 92, LOss : 14.827154\n",
      "Epoch : 93, LOss : 23.239008\n",
      "Epoch : 94, LOss : 11.755982\n",
      "Epoch : 95, LOss : 16.700073\n",
      "Epoch : 96, LOss : 11.449450\n",
      "Epoch : 97, LOss : 9.557568\n",
      "Epoch : 98, LOss : 2.295520\n",
      "Epoch : 99, LOss : 0.012148\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "mdoel = nn.Sequential(\n",
    "    nn.Linear(3072, 512), nn.Tanh(), nn.Linear(512, 2), nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in cifar2:\n",
    "        out = model(img.view(-1).unsqueeze(0))\n",
    "        loss = loss_fn(out, torch.tensor([label]))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch : %d, LOss : %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Loss : 0.038185\n",
      "Epoch : 1, Loss : 0.699414\n",
      "Epoch : 2, Loss : 0.266586\n",
      "Epoch : 3, Loss : 0.512294\n",
      "Epoch : 4, Loss : 0.080110\n",
      "Epoch : 5, Loss : 0.104072\n",
      "Epoch : 6, Loss : 0.720311\n",
      "Epoch : 7, Loss : 0.330848\n",
      "Epoch : 8, Loss : 0.078129\n",
      "Epoch : 9, Loss : 0.561766\n",
      "Epoch : 10, Loss : 0.053830\n",
      "Epoch : 11, Loss : 0.486638\n",
      "Epoch : 12, Loss : 0.979982\n",
      "Epoch : 13, Loss : 0.242778\n",
      "Epoch : 14, Loss : 0.185047\n",
      "Epoch : 15, Loss : 0.386388\n",
      "Epoch : 16, Loss : 0.102807\n",
      "Epoch : 17, Loss : 0.153656\n",
      "Epoch : 18, Loss : 0.430645\n",
      "Epoch : 19, Loss : 0.245167\n",
      "Epoch : 20, Loss : 0.311532\n",
      "Epoch : 21, Loss : 0.388422\n",
      "Epoch : 22, Loss : 0.114615\n",
      "Epoch : 23, Loss : 0.032254\n",
      "Epoch : 24, Loss : 0.634145\n",
      "Epoch : 25, Loss : 0.351809\n",
      "Epoch : 26, Loss : 0.022452\n",
      "Epoch : 27, Loss : 0.367552\n",
      "Epoch : 28, Loss : 0.134817\n",
      "Epoch : 29, Loss : 0.371300\n",
      "Epoch : 30, Loss : 0.109281\n",
      "Epoch : 31, Loss : 0.069391\n",
      "Epoch : 32, Loss : 0.088064\n",
      "Epoch : 33, Loss : 0.057636\n",
      "Epoch : 34, Loss : 0.016943\n",
      "Epoch : 35, Loss : 0.042883\n",
      "Epoch : 36, Loss : 0.054743\n",
      "Epoch : 37, Loss : 0.038451\n",
      "Epoch : 38, Loss : 0.033536\n",
      "Epoch : 39, Loss : 0.136423\n",
      "Epoch : 40, Loss : 0.300368\n",
      "Epoch : 41, Loss : 0.131413\n",
      "Epoch : 42, Loss : 0.020211\n",
      "Epoch : 43, Loss : 0.055137\n",
      "Epoch : 44, Loss : 0.059867\n",
      "Epoch : 45, Loss : 0.011030\n",
      "Epoch : 46, Loss : 0.272859\n",
      "Epoch : 47, Loss : 0.165524\n",
      "Epoch : 48, Loss : 0.544492\n",
      "Epoch : 49, Loss : 0.066699\n",
      "Epoch : 50, Loss : 0.367632\n",
      "Epoch : 51, Loss : 0.077054\n",
      "Epoch : 52, Loss : 0.120180\n",
      "Epoch : 53, Loss : 0.400110\n",
      "Epoch : 54, Loss : 0.177575\n",
      "Epoch : 55, Loss : 0.010782\n",
      "Epoch : 56, Loss : 0.047576\n",
      "Epoch : 57, Loss : 0.100689\n",
      "Epoch : 58, Loss : 0.124960\n",
      "Epoch : 59, Loss : 0.056691\n",
      "Epoch : 60, Loss : 0.326622\n",
      "Epoch : 61, Loss : 0.025136\n",
      "Epoch : 62, Loss : 0.030029\n",
      "Epoch : 63, Loss : 0.245128\n",
      "Epoch : 64, Loss : 0.123128\n",
      "Epoch : 65, Loss : 0.185942\n",
      "Epoch : 66, Loss : 0.094375\n",
      "Epoch : 67, Loss : 0.121309\n",
      "Epoch : 68, Loss : 0.154005\n",
      "Epoch : 69, Loss : 0.036999\n",
      "Epoch : 70, Loss : 0.137657\n",
      "Epoch : 71, Loss : 0.080577\n",
      "Epoch : 72, Loss : 0.297187\n",
      "Epoch : 73, Loss : 0.147765\n",
      "Epoch : 74, Loss : 0.003671\n",
      "Epoch : 75, Loss : 0.173947\n",
      "Epoch : 76, Loss : 0.166508\n",
      "Epoch : 77, Loss : 0.028381\n",
      "Epoch : 78, Loss : 0.599996\n",
      "Epoch : 79, Loss : 0.054454\n",
      "Epoch : 80, Loss : 0.039377\n",
      "Epoch : 81, Loss : 0.048511\n",
      "Epoch : 82, Loss : 0.220704\n",
      "Epoch : 83, Loss : 0.066477\n",
      "Epoch : 84, Loss : 0.127568\n",
      "Epoch : 85, Loss : 0.016421\n",
      "Epoch : 86, Loss : 0.291756\n",
      "Epoch : 87, Loss : 0.242456\n",
      "Epoch : 88, Loss : 0.096392\n",
      "Epoch : 89, Loss : 0.062198\n",
      "Epoch : 90, Loss : 0.017711\n",
      "Epoch : 91, Loss : 0.298406\n",
      "Epoch : 92, Loss : 0.109428\n",
      "Epoch : 93, Loss : 0.103036\n",
      "Epoch : 94, Loss : 0.159649\n",
      "Epoch : 95, Loss : 0.027119\n",
      "Epoch : 96, Loss : 0.057227\n",
      "Epoch : 97, Loss : 0.019681\n",
      "Epoch : 98, Loss : 0.156941\n",
      "Epoch : 99, Loss : 0.175531\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "mdoel = nn.Sequential(\n",
    "    nn.Linear(3072, 128), nn.Tanh(), nn.Linear(128, 2), nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in train_loader:\n",
    "        out = model(img.view(img.shape[0], -1))\n",
    "        loss = loss_fn(out, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch : %d, Loss : %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Loss : 0.018014\n",
      "Epoch : 1, Loss : 0.018784\n",
      "Epoch : 2, Loss : 0.129459\n",
      "Epoch : 3, Loss : 0.097997\n",
      "Epoch : 4, Loss : 0.083308\n",
      "Epoch : 5, Loss : 0.113809\n",
      "Epoch : 6, Loss : 0.094995\n",
      "Epoch : 7, Loss : 0.214036\n",
      "Epoch : 8, Loss : 0.168420\n",
      "Epoch : 9, Loss : 0.568595\n",
      "Epoch : 10, Loss : 0.106334\n",
      "Epoch : 11, Loss : 0.072342\n",
      "Epoch : 12, Loss : 0.060347\n",
      "Epoch : 13, Loss : 0.071979\n",
      "Epoch : 14, Loss : 0.055378\n",
      "Epoch : 15, Loss : 0.006275\n",
      "Epoch : 16, Loss : 0.073337\n",
      "Epoch : 17, Loss : 0.208315\n",
      "Epoch : 18, Loss : 0.118850\n",
      "Epoch : 19, Loss : 0.086371\n",
      "Epoch : 20, Loss : 0.399874\n",
      "Epoch : 21, Loss : 0.276818\n",
      "Epoch : 22, Loss : 0.305124\n",
      "Epoch : 23, Loss : 0.067572\n",
      "Epoch : 24, Loss : 0.269500\n",
      "Epoch : 25, Loss : 0.044284\n",
      "Epoch : 26, Loss : 0.091967\n",
      "Epoch : 27, Loss : 0.257409\n",
      "Epoch : 28, Loss : 0.029445\n",
      "Epoch : 29, Loss : 0.571882\n",
      "Epoch : 30, Loss : 0.156887\n",
      "Epoch : 31, Loss : 0.037059\n",
      "Epoch : 32, Loss : 0.172665\n",
      "Epoch : 33, Loss : 0.145956\n",
      "Epoch : 34, Loss : 0.085551\n",
      "Epoch : 35, Loss : 0.205276\n",
      "Epoch : 36, Loss : 0.030959\n",
      "Epoch : 37, Loss : 0.042567\n",
      "Epoch : 38, Loss : 0.080068\n",
      "Epoch : 39, Loss : 0.034248\n",
      "Epoch : 40, Loss : 0.030214\n",
      "Epoch : 41, Loss : 0.090344\n",
      "Epoch : 42, Loss : 0.190641\n",
      "Epoch : 43, Loss : 0.126016\n",
      "Epoch : 44, Loss : 0.011586\n",
      "Epoch : 45, Loss : 0.071867\n",
      "Epoch : 46, Loss : 0.350917\n",
      "Epoch : 47, Loss : 0.169176\n",
      "Epoch : 48, Loss : 0.074468\n",
      "Epoch : 49, Loss : 0.136142\n",
      "Epoch : 50, Loss : 0.059003\n",
      "Epoch : 51, Loss : 0.065168\n",
      "Epoch : 52, Loss : 0.617632\n",
      "Epoch : 53, Loss : 0.065943\n",
      "Epoch : 54, Loss : 0.051980\n",
      "Epoch : 55, Loss : 0.128283\n",
      "Epoch : 56, Loss : 0.092253\n",
      "Epoch : 57, Loss : 0.085102\n",
      "Epoch : 58, Loss : 0.047993\n",
      "Epoch : 59, Loss : 0.176559\n",
      "Epoch : 60, Loss : 0.008638\n",
      "Epoch : 61, Loss : 0.098007\n",
      "Epoch : 62, Loss : 0.111475\n",
      "Epoch : 63, Loss : 0.143963\n",
      "Epoch : 64, Loss : 0.025675\n",
      "Epoch : 65, Loss : 0.049433\n",
      "Epoch : 66, Loss : 0.161200\n",
      "Epoch : 67, Loss : 0.053182\n",
      "Epoch : 68, Loss : 0.021299\n",
      "Epoch : 69, Loss : 0.011973\n",
      "Epoch : 70, Loss : 0.042681\n",
      "Epoch : 71, Loss : 0.098465\n",
      "Epoch : 72, Loss : 0.146412\n",
      "Epoch : 73, Loss : 0.092168\n",
      "Epoch : 74, Loss : 0.118989\n",
      "Epoch : 75, Loss : 0.051779\n",
      "Epoch : 76, Loss : 0.029381\n",
      "Epoch : 77, Loss : 0.022885\n",
      "Epoch : 78, Loss : 0.230974\n",
      "Epoch : 79, Loss : 0.085390\n",
      "Epoch : 80, Loss : 0.103052\n",
      "Epoch : 81, Loss : 0.085197\n",
      "Epoch : 82, Loss : 0.078789\n",
      "Epoch : 83, Loss : 0.127567\n",
      "Epoch : 84, Loss : 0.113789\n",
      "Epoch : 85, Loss : 0.263089\n",
      "Epoch : 86, Loss : 0.120402\n",
      "Epoch : 87, Loss : 0.014884\n",
      "Epoch : 88, Loss : 0.062081\n",
      "Epoch : 89, Loss : 0.193159\n",
      "Epoch : 90, Loss : 0.201587\n",
      "Epoch : 91, Loss : 0.123946\n",
      "Epoch : 92, Loss : 0.419557\n",
      "Epoch : 93, Loss : 0.058113\n",
      "Epoch : 94, Loss : 0.090036\n",
      "Epoch : 95, Loss : 0.039892\n",
      "Epoch : 96, Loss : 0.060350\n",
      "Epoch : 97, Loss : 0.087942\n",
      "Epoch : 98, Loss : 0.245372\n",
      "Epoch : 99, Loss : 0.326079\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "mdoel = nn.Sequential(\n",
    "    nn.Linear(3072, 512), nn.Tanh(), nn.Linear(512, 2), nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in train_loader:\n",
    "        out = model(img.view(img.shape[0], -1))\n",
    "        loss = loss_fn(out, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch : %d, Loss : %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 tensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "128 tensor([0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0])\n",
      "192 tensor([1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0])\n",
      "256 tensor([1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0])\n",
      "320 tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0])\n",
      "384 tensor([0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1])\n",
      "448 tensor([0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1])\n",
      "512 tensor([0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0])\n",
      "576 tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0])\n",
      "640 tensor([1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0])\n",
      "704 tensor([0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1])\n",
      "768 tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0])\n",
      "832 tensor([0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0])\n",
      "896 tensor([1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1])\n",
      "960 tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])\n",
      "1024 tensor([0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "1088 tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1])\n",
      "1152 tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0])\n",
      "1216 tensor([0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0])\n",
      "1280 tensor([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1])\n",
      "1344 tensor([1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])\n",
      "1408 tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1])\n",
      "1472 tensor([0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1])\n",
      "1536 tensor([1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1])\n",
      "1600 tensor([0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1])\n",
      "1664 tensor([1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1])\n",
      "1728 tensor([1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1])\n",
      "1792 tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0])\n",
      "1856 tensor([0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1])\n",
      "1920 tensor([1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1])\n",
      "1984 tensor([1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1])\n",
      "2048 tensor([1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0])\n",
      "2112 tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1])\n",
      "2176 tensor([1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0])\n",
      "2240 tensor([1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0])\n",
      "2304 tensor([0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0])\n",
      "2368 tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1])\n",
      "2432 tensor([0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1])\n",
      "2496 tensor([0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0])\n",
      "2560 tensor([0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "2624 tensor([1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0])\n",
      "2688 tensor([1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0])\n",
      "2752 tensor([1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0])\n",
      "2816 tensor([1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1])\n",
      "2880 tensor([0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1])\n",
      "2944 tensor([1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0])\n",
      "3008 tensor([1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0])\n",
      "3072 tensor([0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1])\n",
      "3136 tensor([1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1])\n",
      "3200 tensor([0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1])\n",
      "3264 tensor([0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0])\n",
      "3328 tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1])\n",
      "3392 tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1])\n",
      "3456 tensor([0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1])\n",
      "3520 tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1])\n",
      "3584 tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1])\n",
      "3648 tensor([1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "3712 tensor([1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1])\n",
      "3776 tensor([0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "3840 tensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0])\n",
      "3904 tensor([0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0])\n",
      "3968 tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1])\n",
      "4032 tensor([1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0])\n",
      "4096 tensor([1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1])\n",
      "4160 tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1])\n",
      "4224 tensor([1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1])\n",
      "4288 tensor([0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0])\n",
      "4352 tensor([0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0])\n",
      "4416 tensor([1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1])\n",
      "4480 tensor([0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0])\n",
      "4544 tensor([0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1])\n",
      "4608 tensor([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1])\n",
      "4672 tensor([0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0])\n",
      "4736 tensor([0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1])\n",
      "4800 tensor([1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n",
      "4864 tensor([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "4928 tensor([0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0])\n",
      "4992 tensor([1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1])\n",
      "5056 tensor([1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1])\n",
      "5120 tensor([0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0])\n",
      "5184 tensor([1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
      "5248 tensor([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1])\n",
      "5312 tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0])\n",
      "5376 tensor([0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1])\n",
      "5440 tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0])\n",
      "5504 tensor([1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
      "5568 tensor([1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0])\n",
      "5632 tensor([1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1])\n",
      "5696 tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0])\n",
      "5760 tensor([1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0])\n",
      "5824 tensor([1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1])\n",
      "5888 tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0])\n",
      "5952 tensor([0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1])\n",
      "6016 tensor([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1])\n",
      "6080 tensor([0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0])\n",
      "6144 tensor([0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1])\n",
      "6208 tensor([1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0])\n",
      "6272 tensor([1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1])\n",
      "6336 tensor([1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0])\n",
      "6400 tensor([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0])\n",
      "6464 tensor([1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0])\n",
      "6528 tensor([0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1])\n",
      "6592 tensor([1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
      "6656 tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])\n",
      "6720 tensor([0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0])\n",
      "6784 tensor([1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0])\n",
      "6848 tensor([1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1])\n",
      "6912 tensor([0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1])\n",
      "6976 tensor([0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0])\n",
      "7040 tensor([1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0])\n",
      "7104 tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0])\n",
      "7168 tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1])\n",
      "7232 tensor([0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1])\n",
      "7296 tensor([1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1])\n",
      "7360 tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0])\n",
      "7424 tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0])\n",
      "7488 tensor([1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0])\n",
      "7552 tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1])\n",
      "7616 tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1])\n",
      "7680 tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0])\n",
      "7744 tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1])\n",
      "7808 tensor([1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1])\n",
      "7872 tensor([1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1])\n",
      "7936 tensor([0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0])\n",
      "8000 tensor([1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1])\n",
      "8064 tensor([1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0])\n",
      "8128 tensor([0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0])\n",
      "8192 tensor([0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0])\n",
      "8256 tensor([0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1])\n",
      "8320 tensor([0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1])\n",
      "8384 tensor([1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0])\n",
      "8448 tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0])\n",
      "8512 tensor([1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0])\n",
      "8576 tensor([0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0])\n",
      "8640 tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1])\n",
      "8704 tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1])\n",
      "8768 tensor([1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0])\n",
      "8832 tensor([0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0])\n",
      "8896 tensor([1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1])\n",
      "8960 tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1])\n",
      "9024 tensor([0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])\n",
      "9088 tensor([0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0])\n",
      "9152 tensor([0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0])\n",
      "9216 tensor([1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1])\n",
      "9280 tensor([1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1])\n",
      "9344 tensor([0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1])\n",
      "9408 tensor([0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0])\n",
      "9472 tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0])\n",
      "9536 tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1])\n",
      "9600 tensor([0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0])\n",
      "9664 tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0])\n",
      "9728 tensor([0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0])\n",
      "9792 tensor([1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1])\n",
      "9856 tensor([0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0])\n",
      "9920 tensor([0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
      "9984 tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1])\n",
      "10000 tensor([1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1])\n",
      "Accuracy: 0.963300\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        print(total, labels)\n",
    "        correct += int((predicted == labels).sum())\n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.752500\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "\n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.497427\n",
      "Epoch: 1, Loss: 0.615837\n",
      "Epoch: 2, Loss: 0.436824\n",
      "Epoch: 3, Loss: 0.347781\n",
      "Epoch: 4, Loss: 0.577657\n",
      "Epoch: 5, Loss: 0.411738\n",
      "Epoch: 6, Loss: 0.508799\n",
      "Epoch: 7, Loss: 0.461894\n",
      "Epoch: 8, Loss: 0.512662\n",
      "Epoch: 9, Loss: 0.538019\n",
      "Epoch: 10, Loss: 0.169521\n",
      "Epoch: 11, Loss: 0.142382\n",
      "Epoch: 12, Loss: 0.742934\n",
      "Epoch: 13, Loss: 0.645561\n",
      "Epoch: 14, Loss: 0.776193\n",
      "Epoch: 15, Loss: 0.387493\n",
      "Epoch: 16, Loss: 0.332133\n",
      "Epoch: 17, Loss: 0.302807\n",
      "Epoch: 18, Loss: 0.791955\n",
      "Epoch: 19, Loss: 0.145664\n",
      "Epoch: 20, Loss: 0.198251\n",
      "Epoch: 21, Loss: 0.401624\n",
      "Epoch: 22, Loss: 0.078391\n",
      "Epoch: 23, Loss: 0.232259\n",
      "Epoch: 24, Loss: 0.142118\n",
      "Epoch: 25, Loss: 0.523029\n",
      "Epoch: 26, Loss: 0.368597\n",
      "Epoch: 27, Loss: 0.216721\n",
      "Epoch: 28, Loss: 0.712369\n",
      "Epoch: 29, Loss: 0.253066\n",
      "Epoch: 30, Loss: 0.096683\n",
      "Epoch: 31, Loss: 0.276528\n",
      "Epoch: 32, Loss: 0.082747\n",
      "Epoch: 33, Loss: 0.232660\n",
      "Epoch: 34, Loss: 0.274998\n",
      "Epoch: 35, Loss: 0.205447\n",
      "Epoch: 36, Loss: 0.057985\n",
      "Epoch: 37, Loss: 0.108904\n",
      "Epoch: 38, Loss: 0.190054\n",
      "Epoch: 39, Loss: 0.082992\n",
      "Epoch: 40, Loss: 0.061353\n",
      "Epoch: 41, Loss: 0.035270\n",
      "Epoch: 42, Loss: 0.036307\n",
      "Epoch: 43, Loss: 0.213788\n",
      "Epoch: 44, Loss: 1.282373\n",
      "Epoch: 45, Loss: 0.139283\n",
      "Epoch: 46, Loss: 0.017974\n",
      "Epoch: 47, Loss: 0.180210\n",
      "Epoch: 48, Loss: 0.029747\n",
      "Epoch: 49, Loss: 0.065336\n",
      "Epoch: 50, Loss: 0.213441\n",
      "Epoch: 51, Loss: 0.035705\n",
      "Epoch: 52, Loss: 0.035820\n",
      "Epoch: 53, Loss: 0.047568\n",
      "Epoch: 54, Loss: 0.882827\n",
      "Epoch: 55, Loss: 0.036545\n",
      "Epoch: 56, Loss: 0.177645\n",
      "Epoch: 57, Loss: 0.013025\n",
      "Epoch: 58, Loss: 0.002553\n",
      "Epoch: 59, Loss: 0.036788\n",
      "Epoch: 60, Loss: 0.012225\n",
      "Epoch: 61, Loss: 0.008952\n",
      "Epoch: 62, Loss: 0.011366\n",
      "Epoch: 63, Loss: 0.009077\n",
      "Epoch: 64, Loss: 0.065654\n",
      "Epoch: 65, Loss: 0.005660\n",
      "Epoch: 66, Loss: 0.019235\n",
      "Epoch: 67, Loss: 0.005216\n",
      "Epoch: 68, Loss: 0.002939\n",
      "Epoch: 69, Loss: 0.004583\n",
      "Epoch: 70, Loss: 0.001648\n",
      "Epoch: 71, Loss: 0.007859\n",
      "Epoch: 72, Loss: 0.245502\n",
      "Epoch: 73, Loss: 0.037202\n",
      "Epoch: 74, Loss: 0.001811\n",
      "Epoch: 75, Loss: 0.001157\n",
      "Epoch: 76, Loss: 0.005367\n",
      "Epoch: 77, Loss: 0.011743\n",
      "Epoch: 78, Loss: 0.002640\n",
      "Epoch: 79, Loss: 0.001710\n",
      "Epoch: 80, Loss: 0.000723\n",
      "Epoch: 81, Loss: 0.005251\n",
      "Epoch: 82, Loss: 0.032440\n",
      "Epoch: 83, Loss: 0.005759\n",
      "Epoch: 84, Loss: 0.006570\n",
      "Epoch: 85, Loss: 0.000764\n",
      "Epoch: 86, Loss: 0.001390\n",
      "Epoch: 87, Loss: 0.000870\n",
      "Epoch: 88, Loss: 0.002692\n",
      "Epoch: 89, Loss: 0.001187\n",
      "Epoch: 90, Loss: 0.002375\n",
      "Epoch: 91, Loss: 0.001489\n",
      "Epoch: 92, Loss: 0.000340\n",
      "Epoch: 93, Loss: 0.002333\n",
      "Epoch: 94, Loss: 0.001859\n",
      "Epoch: 95, Loss: 0.000785\n",
      "Epoch: 96, Loss: 0.000564\n",
      "Epoch: 97, Loss: 0.000536\n",
      "Epoch: 98, Loss: 0.004845\n",
      "Epoch: 99, Loss: 0.000679\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 1024),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(128, 2),\n",
    ")\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "\n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.809000\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "\n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3737474"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3737474"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters() if p.requires_grad == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 3072]), torch.Size([1024]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(3072, 1024)\n",
    "linear.weight.shape, linear.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 3, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3, 16, kernel_size=3)\n",
    "conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = cifar2[0]\n",
    "output = conv(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.6139, -0.3228,  ..., -0.2752, -0.5451],\n",
       "          [ 0.6615, -0.1482,  ..., -0.3228, -0.5768],\n",
       "          ...,\n",
       "          [ 0.5980,  0.4393,  ..., -0.4340,  0.0265],\n",
       "          [ 0.9156,  0.8044,  ..., -0.5451, -0.0529]],\n",
       "\n",
       "         [[ 1.3369,  0.2740,  ...,  0.3867,  0.0968],\n",
       "          [ 1.4497,  0.5961,  ...,  0.3062,  0.0646],\n",
       "          ...,\n",
       "          [ 0.5478,  0.6605,  ...,  0.4028,  0.8860],\n",
       "          [ 0.4834,  0.9504,  ...,  0.1613,  0.7572]],\n",
       "\n",
       "         [[-0.4487, -0.7935,  ..., -0.6736, -0.8535],\n",
       "          [-0.4487, -0.9734,  ..., -0.6286, -0.8535],\n",
       "          ...,\n",
       "          [-0.4337, -0.4787,  ..., -1.3032, -0.9884],\n",
       "          [-0.1789,  0.0310,  ..., -1.3182, -1.0484]]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 16, 30, 30]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.permute(1, 2, 0), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detach():\n",
    "This removes the tensor from the computational graph (used in PyTorch), meaning the tensor is no longer connected to the computation of gradients. This is necessary if output is the result of a forward pass in a neural network and you're only interested in displaying the image without computing further gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(output[0, 0].detach(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "output = conv(img.unsqueeze(0))\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.weight.fill_(1.0 / 9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0, 0].detach(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv.weight[:] = torch.tensor(\n",
    "        [[-1.0, 0.0, 1.0], [-1.0, 0.0, 1.0], [-1.0, 0.0, 1.0]]\n",
    "    )\n",
    "    conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApy0lEQVR4nO3dfWzVZZr/8c8B2tOn00NLH05rS9NBcFWQieIgrKPIDI2dDNFhJkFNJpCdMaOACcGJs+gmNpssNW4kTMLK7s5MGMzI4B+jjomO2glSZsKyASIrQddgKFJCa0ufH0+fvvuHP85vyuN9QQ93e3i/kpNIe3lxf8/9Pefi257zOaEgCAIBAODBNN8LAADcvBhCAABvGEIAAG8YQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvZvhewIXGxsZ09uxZRSIRhUIh38sBABgFQaCenh6VlpZq2rQrX+tMuiF09uxZlZeX+14GAOA6NTY2qqys7Io1SRtCr776qv71X/9VTU1NuvPOO7Vt2zZ9+9vfvur/F4lEJEn/9E//pIyMDKe/68yZM87r+uY3v+lcK0mZmZnOtQMDA6beaWlpzrWu98V5V/vXx99qb2839W5sbDTVT58+3bl21qxZpt4WIyMjpvr09HTnWsteStLw8LCp3pKuZTlnJdu50tfXZ+rd09OTlFpJys7Odq7Ny8sz9bYep2U/rT/hGR0dda4Nh8Om3pbHREFBgXPtwMCAnn322cTz+ZUkZQi98cYb2rhxo1599VX9/d//vf7jP/5D1dXV+vTTTzV79uwr/r/nNygjI8P5iddyx1sfoFlZWaZ6C8uTXDKHkHV4Wk/0GTPcTzPr/lhMpiFkuU+kyTOExsbGTL0tT85DQ0Om3pbHhPU+sTzxS7Z/aE3VIXQtj02XY03KCxO2bt2qn/zkJ/rpT3+q22+/Xdu2bVN5ebl27NiRjL8OADBFTfgQGhoa0pEjR1RVVTXu61VVVTpw4MBF9fF4XN3d3eNuAICbw4QPoXPnzml0dFTFxcXjvl5cXKzm5uaL6mtraxWNRhM3XpQAADePpL1P6MKfBQZBcMmfD27evFldXV2Jm/WX3gCAqWvCX5hQUFCg6dOnX3TV09LSctHVkfT1L9Ksv0wDAKSGCb8SSk9P1z333KO6urpxX6+rq9PSpUsn+q8DAExhSXmJ9qZNm/TjH/9YixYt0pIlS/Sf//mfOn36tJ566qlk/HUAgCkqKUNo9erVamtr0z//8z+rqalJ8+fP13vvvaeKiopk/HUAgCkqaYkJ69at07p16675/09LS3N+A6DlDVfWNwla3hDX2tpq6m15V7b1VYMzZ850ro3H46beVpY321nelCnZ9t76JkHL3lvfrGqtt+yR9Y2WyXyzan9/v3Ot9UVJpaWlzrXf+MY3TL0HBwdN9Za3llje2CrZ9sf6WLbU5+TkONda1kyKNgDAG4YQAMAbhhAAwBuGEADAG4YQAMAbhhAAwBuGEADAG4YQAMAbhhAAwBuGEADAm6TF9lyvzMxM5880t0Ta9PT0mNYxPDzsXDs0NGTq3dXV5VxricGQpKKiIufa2bNnm3q3t7eb6r/88kvn2o6ODlPv3Nxc59pIJGLqbYkpscZBWWNhLPeLNZ4oGo0611qP06KpqclUb4mmisVipt7WT3huaWlxrrXG9lhYn4MssrKyktKXKyEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCAN5M2O87izjvvdK5tbm429W5tbXWuTU9PN/UeGxtzrrWuu7e317k2IyPD1NvKkk1mXUs4HHautWTBSVJ2drZzrWUvJamzszNp9daMvLS0NOdaa+adJSfNktMo2XLSLMco2fPdRkdHnWut54qFdX8s54rl8WPJL+RKCADgDUMIAOANQwgA4A1DCADgDUMIAOANQwgA4A1DCADgDUMIAOANQwgA4A1DCADgzaSN7enq6lI8HneqvfXWW537WuIkrIqKikz1M2a43/1ffPGFqfeZM2ecaysqKky9rfEqlsiUvLw8U+9p05L376ggCJxrLbEtktTX12eqd30sSFJBQYGptyWipqOjw9Tbsu6ysjJT78LCQufarq4uU29rveUct56zyYwnskRTJQtXQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvJnV23ODgoFOtJZ/Kmq0UDoeda625dCUlJaZ6C8t90tzcbOptzQ+z3IdZWVmm3v39/c61vb29pt6WbD9L/pq1t2TL1EtPTzf1bm1tda793//9X1Nvy/0yZ84cU+9YLOZca917a75bJBJxrh0bGzP1HhkZca61PNYk27liyUe01HIlBADwZsKHUE1NjUKh0Lib5V8sAICbR1J+HHfnnXfqz3/+c+LP1h9VAABuDkkZQjNmzODqBwBwVUn5ndCJEydUWlqqyspKPfbYYzp58uRla+PxuLq7u8fdAAA3hwkfQosXL9Zrr72mDz74QL/61a/U3NyspUuXqq2t7ZL1tbW1ikajiVt5eflELwkAMElN+BCqrq7WD3/4Qy1YsEDf/e539e6770qSdu3adcn6zZs3q6urK3FrbGyc6CUBACappL9PKDs7WwsWLNCJEycu+f1wOGx+bTsAIDUk/X1C8Xhcn332WVLfmAkAmJomfAj9/Oc/V319vRoaGvTf//3f+tGPfqTu7m6tWbNmov8qAMAUN+E/jjtz5owef/xxnTt3ToWFhbrvvvt08OBBVVRUmPr09/c7Rz8MDw8797XGpViieHp6eky98/PznWuLiopMvS0xJdYoo9zcXFP9uXPnklIr2WJHgiAw9bbEq1jvw+zsbFO9JUbGGh/V0tLiXHu5H6tfTmFhoXPtAw88YOptOQ+HhoZMvTMzM031lnOrq6vL1NtyHlrPK8vzoeV51vSc7FzpaM+ePRPdEgCQosiOAwB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4k/SPcrhWY2NjzplJlmyl6dOnm9fhqrW11dQ7IyPDuba4uNjU27Jua6aaNTvOkpVlybyTbPl71jwwS66Wa87heZb9sbL2ttzn1v25/fbbnWut55XlPrc81iR7DqTlE6H7+vpMvS35iNZz3NLbcl5ZarkSAgB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4M2lje0ZHRzUyMuJUa4mIsMRUSFJOTo5zbXt7u6l3R0eHc601dmRwcNC51hJPI9nuE0mqqKhwrnXd8/NCoZBzbTgcNvW2nCuWaCLJHn9jOcetx2k5V6zn4aJFi5xrY7GYqfdnn33mXGuN6zpz5oypvqWlxbnW+hyUnZ3tXGuN7bFIVhQYV0IAAG8YQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvGEIAAG8YQgAAbyZtdtzw8LBzLpglh8uaqxWJRJxrLRlPkjQ0NJSUWsmWB2fNPbNmzZWVlTnXpqWlmXq3trY611ryrCQpHo871w4MDJh69/f3m+ot+5+fn2/qbcnrKy4uNvW+++67nWutuXTd3d3OtdbHfU9Pj6nesp/Wc9yy9mnTbNcVw8PDzrWWx4OllishAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDeTNjtucHBQY2NjTrWWvCRLTpa1d15enqm3JbPNmh2Xm5vrXGvNybJmsFkywaz5Ye3t7c611nw3S66Wtbcl90yyZZNZ70NLNlllZaWp96xZs5xrrfdhenq6c6017zAnJ8dUb3leseRRStL06dOda62ZhIODg861fX19zrWWveRKCADgjXkI7d+/XytXrlRpaalCoZDefvvtcd8PgkA1NTUqLS1VZmamli1bpuPHj0/UegEAKcQ8hPr6+rRw4UJt3779kt9/+eWXtXXrVm3fvl2HDh1SLBbTihUrzD/yAQCkPvPvhKqrq1VdXX3J7wVBoG3btumFF17QqlWrJEm7du1ScXGxdu/erZ/97GfXt1oAQEqZ0N8JNTQ0qLm5WVVVVYmvhcNhPfjggzpw4MAl/594PK7u7u5xNwDAzWFCh1Bzc7Okiz99sbi4OPG9C9XW1ioajSZu5eXlE7kkAMAklpRXx134sdxBEFz2o7o3b96srq6uxK2xsTEZSwIATEIT+j6hWCwm6esropKSksTXW1paLvvZ9OFw2Pz57wCA1DChV0KVlZWKxWKqq6tLfG1oaEj19fVaunTpRP5VAIAUYL4S6u3t1RdffJH4c0NDg44ePar8/HzNnj1bGzdu1JYtWzR37lzNnTtXW7ZsUVZWlp544okJXTgAYOozD6HDhw/roYceSvx506ZNkqQ1a9bot7/9rZ577jkNDAxo3bp16ujo0OLFi/Xhhx+aoypGRkYu+3ukC7nWSdLo6KhpHZZ6a1xKb2+vc60l4keSMjMznWsLCgpMva0/PrVEH1lfHeka7XQtLPf52bNnTb0tcUOSlJaW5lxreTxIUmFhoXNtfn6+qbclbqqzs9PU2xKtY4n4kS5+cdXVzJw507nWEsMj2aJ1LM8pki3OqKGhwbk2Ho+7r8G58v9ZtmzZFbPDQqGQampqVFNTY20NALjJkB0HAPCGIQQA8IYhBADwhiEEAPCGIQQA8IYhBADwhiEEAPCGIQQA8IYhBADwhiEEAPBmQj/KYSKlpaU55z1ZssyGh4dN60jmJ71acukGBgZMvXNzc51rKysrTb2tWXOW+9CaqWbJjrPkmEm27Lhz586Zelv3s6ioyLnWmh1nyQ8rLS019bbkpFnzES2smZGW+0SSotGoc60l806S6TPWrPl7eXl5zrUtLS3OtZbHGldCAABvGEIAAG8YQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvJm1sz4wZM5yjMyzRLVaWmB9rNIhrLJF1Hdb6rKwsU++ZM2ea6i1RItY4G8veJ/M8ycjIMNVbY2EsUS/9/f2m3qdPn3auveOOO0y9LXFD//M//2Pq3dra6lxr3Z+RkRFT/axZs5xrI5GIqbdl7dbnoCAInGstEUyWWq6EAADeMIQAAN4whAAA3jCEAADeMIQAAN4whAAA3jCEAADeMIQAAN4whAAA3jCEAADeMIQAAN5M2uw4i8HBQedaS6aRJIXDYedaa2aXJbfJmjWWm5vrXGs5Rknq7e011cfjcefaadNs/y6yZORZ1iHZ7vPi4mJTb+txWvaoubnZ1PvEiRPOtd/61rdMvZN5Hlry3ayZhNYMNstz0Llz55K2lmg0auqdlpbmXGvJsLOc31wJAQC8YQgBALxhCAEAvGEIAQC8YQgBALxhCAEAvGEIAQC8YQgBALxhCAEAvGEIAQC8mbSxPZmZmUpPT3eqtcR3WGIqJCkrK8u5dmxszNS7r6/PudZyjJItcsYaUdLU1GSq7+zsdK5NZmyPNbrFEiOTk5Nj6m2NYQqFQs61lggZyRY3ZdlLyRbxZI3tsTyWrXFdlse9ZIvgsj5+LL1jsZipt+U5y3JeDQ0NOddyJQQA8IYhBADwxjyE9u/fr5UrV6q0tFShUEhvv/32uO+vXbtWoVBo3O2+++6bqPUCAFKIeQj19fVp4cKF2r59+2VrHn74YTU1NSVu77333nUtEgCQmswvTKiurlZ1dfUVa8LhsPkXZACAm09Sfie0b98+FRUVad68eXryySfV0tJy2dp4PK7u7u5xNwDAzWHCh1B1dbVef/117d27V6+88ooOHTqk5cuXX/ZTLWtraxWNRhO38vLyiV4SAGCSmvD3Ca1evTrx3/Pnz9eiRYtUUVGhd999V6tWrbqofvPmzdq0aVPiz93d3QwiALhJJP3NqiUlJaqoqLjs59iHw2Hzm9QAAKkh6e8TamtrU2Njo0pKSpL9VwEAphjzlVBvb6+++OKLxJ8bGhp09OhR5efnKz8/XzU1NfrhD3+okpISnTp1Ss8//7wKCgr0gx/8YEIXDgCY+sxD6PDhw3rooYcSfz7/+5w1a9Zox44dOnbsmF577TV1dnaqpKREDz30kN544w1FIhHT31NWVqaMjAynWkvemDWbzDW/TtJlX3xxOR0dHUmplaTCwkLn2ra2NlPv9vZ2U70lR8qa8WXJs7LkzElyPv8ke26gdS3Z2dnOtZa9t9Zb8/csWXOZmZmm3pb70PrYLC0tNdVb1m5di+XXFdZ1W3IjLVmXlr0xD6Fly5ZdMVDvgw8+sLYEANykyI4DAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4wxACAHiT9I9yuFYLFixwzss6e/asc19rbpMlEywUCpl6t7a2OteePHnS1DsnJ8e51prZZcmCk3TFmKcLWT/WIysry7nWmntmOU7reWW9Dy3noWXvpa9zGl1ZzxVLNpk1N7Cnp8e5tre319R71qxZpvri4mLn2vz8fFNvy95bszEt+YiW/E/L+c2VEADAG4YQAMAbhhAAwBuGEADAG4YQAMAbhhAAwBuGEADAG4YQAMAbhhAAwBuGEADAm0kb2zNnzhznmIjTp08797XGq1hiMKyxIx0dHc61n376qam3JUZk4cKFpt5WlsgUSzSIJOXl5TnXWuJPJKmlpcW5dnBw0NR7ZGTEVD9jhvtDNTc319S7oKDAuTYajZp6W+5zS8SPZIts6uzsNPW27L0kFRYWOtda96e/v9+5tr293dTbEiE0e/Zs51rL44ErIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3kzY7Ljc31zljqa+vz7mvNbMrLS3NuTYzM9PU27Lus2fPmnoPDw87186cOdPUu7W11VTf1tbmXFtWVmbqbcmaGxgYMPW2ZJlZ7m9JCoVCpnpLBpv1HLfkh5WUlJh6Dw0NOdda98eybmtv6/5YMtuSufeWPErJ9vxmyWm03N9cCQEAvGEIAQC8YQgBALxhCAEAvGEIAQC8YQgBALxhCAEAvGEIAQC8YQgBALxhCAEAvJm0sT1BECgIAqdaSzSIJYrl/DpczZhhuzstcRzWdefk5DjXhsNhU+9kxvZY42+mTXP/d5QlokSy7ac1isV6rljWbj3OgoIC59o5c+aYelvibKznVVZWlnNtYWFh0npLtqik3t7epPW2RBlJtucgy/Os5XHMlRAAwBvTEKqtrdW9996rSCSioqIiPfroo/r888/H1QRBoJqaGpWWliozM1PLli3T8ePHJ3TRAIDUYBpC9fX1Wr9+vQ4ePKi6ujqNjIyoqqpqXBr0yy+/rK1bt2r79u06dOiQYrGYVqxYoZ6englfPABgajP9YPr9998f9+edO3eqqKhIR44c0QMPPKAgCLRt2za98MILWrVqlSRp165dKi4u1u7du/Wzn/1s4lYOAJjyrut3Ql1dXZL+/y/DGhoa1NzcrKqqqkRNOBzWgw8+qAMHDlyyRzweV3d397gbAODmcM1DKAgCbdq0Sffff7/mz58vSWpubpYkFRcXj6stLi5OfO9CtbW1ikajiVt5efm1LgkAMMVc8xDasGGDPvnkE/3+97+/6HsXvlw1CILLvoR18+bN6urqStwaGxuvdUkAgCnmmt4n9Mwzz+idd97R/v37x30ccywWk/T1FdHffgxwS0vLRVdH54XDYfP7VAAAqcF0JRQEgTZs2KA333xTe/fuVWVl5bjvV1ZWKhaLqa6uLvG1oaEh1dfXa+nSpROzYgBAyjBdCa1fv167d+/WH//4R0UikcTveaLRqDIzMxUKhbRx40Zt2bJFc+fO1dy5c7VlyxZlZWXpiSeeSMoBAACmLtMQ2rFjhyRp2bJl476+c+dOrV27VpL03HPPaWBgQOvWrVNHR4cWL16sDz/8UJFIZEIWDABIHaYh5JKjFgqFVFNTo5qammtdk6Svs9IsmUnJ0t/f71xrXa8ln2revHmm3pbsuJMnT5p6W7LgJFuW2cDAgKl3Mt8EnZGRkbR1RKNRU31eXp5zreWctfY+/3tfVw0NDc6159/y4cqyP9YsuAt/1XA1l3v176WcOXPG1HtwcNC51pIDKNny4Cxvn4nH4861ZMcBALxhCAEAvGEIAQC8YQgBALxhCAEAvGEIAQC8YQgBALxhCAEAvGEIAQC8YQgBALy5po9yuBFGR0c1OjrqVGuJhRkbGzOtwxIj4xJr9Ldyc3OdaysqKky9Z86c6Vzb19dn6j19+nRTvSVC6KuvvjL1tsTlWCNnLNEjlmgVSZozZ46p3nLeWiJkJCk7O9u51poBablfrOeh6/ODZHuOkOyPZct9aIkbkmxxOcPDw6belvvcEvFjqeVKCADgDUMIAOANQwgA4A1DCADgDUMIAOANQwgA4A1DCADgDUMIAOANQwgA4A1DCADgDUMIAOBNSmTHWbLMrBlSlnpLlpUkjYyMONdmZmaaelsyvtLT0029LZl3klRUVORce+bMGVPv9vZ259pbbrnF1Lujo8O51prZZc2Oa2hocK615tjNmOH+NPDll1+aelv2x5K/Jtke96FQyNTbsm5r/4KCAlNvy3FOm2a7rmhpaXGutTxfWWq5EgIAeMMQAgB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeMMQAgB4wxACAHjDEAIAeDNpY3uGh4fNUSgurPEdljX09/ebelsiNizRHZIUj8eda8vLy029rcc5c+ZM59q2tjZTb0t9X1+fqXdPT49zrSUmSZKi0aip3nKc1nNlbGzMufbIkSOm3r29vc61sVjM1NuynwMDA6benZ2dpvqMjAznWmtM1rx585xrw+GwqffRo0eday334dDQkHMtV0IAAG8YQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvGEIAAG8YQgAAbyZtdlx/f79zttrIyIhzX0umkWTLp+rq6jL1zsnJca615k11d3c71w4ODpp6z5hhO20seX233XabqfepU6ecazs6Oky9LedVSUmJqXcQBKb6lpaWpPW23C8NDQ2m3qOjo8612dnZpt6WjDzrY9OSvSjZciAt55Uk3XLLLc611kxCS3ac5bmT7DgAwJRgGkK1tbW69957FYlEVFRUpEcffVSff/75uJq1a9cqFAqNu913330TumgAQGowDaH6+nqtX79eBw8eVF1dnUZGRlRVVXXRj6wefvhhNTU1JW7vvffehC4aAJAaTD/cf//998f9eefOnSoqKtKRI0f0wAMPJL4eDofNnw0CALj5XNfvhM7/si8/P3/c1/ft26eioiLNmzdPTz755BV/qRqPx9Xd3T3uBgC4OVzzEAqCQJs2bdL999+v+fPnJ75eXV2t119/XXv37tUrr7yiQ4cOafny5Zd9tUltba2i0WjiZv2UTwDA1HXNL9HesGGDPvnkE/31r38d9/XVq1cn/nv+/PlatGiRKioq9O6772rVqlUX9dm8ebM2bdqU+HN3dzeDCABuEtc0hJ555hm988472r9/v8rKyq5YW1JSooqKCp04ceKS3w+Hw+bPRQcApAbTEAqCQM8884zeeust7du3T5WVlVf9f9ra2tTY2Gh+Mx8AIPWZfie0fv16/e53v9Pu3bsViUTU3Nys5uZmDQwMSJJ6e3v185//XP/1X/+lU6dOad++fVq5cqUKCgr0gx/8ICkHAACYukxXQjt27JAkLVu2bNzXd+7cqbVr12r69Ok6duyYXnvtNXV2dqqkpEQPPfSQ3njjDUUikQlbNAAgNZh/HHclmZmZ+uCDD65rQed1dXU5ZyxZss+smVCW7DhrJlRRUZFzbVZWlqn3V1995VxrfVl8RkaGqd7C+qKUtrY259qTJ0+aelvywKzvi7OcV5ItJ83Kcr+c/6mHq8LCQudaayah5fFmvb+tj+W0tDTnWuvvwC0Zk7m5uabelrVY9mdsbMy5luw4AIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA31/x5QsnW1dWl4eFhp1pLRMTVoocuZIlLsUZmWKJ4LNEdki1iwxpR0tPTY6q/5ZZbnGtnzpxp6m2JELrSJ/xeimXvrVFGlqgpybb/1t6WiCdrfJTlMWFdt+W8DYVCpt5nz5411Vv633777abelvulvb3d1NvyeCstLXWutayZKyEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCANwwhAIA3DCEAgDcMIQCAN5M2O667u9s5G8qSk5aenm5ahyUvyZrBNjo66lxrzbyLRCLOtefOnTP1bmtrM9VbsuMsOYCSFA6HnWvz8/NNvePxuHNtV1eXqbc148uy9rS0NFPvU6dOOdd2dHSYeluyyazrtjzurZl31uPMzs52rrVmTPb29jrXWnIAJSkvL8+51vIcNDAw4FzLlRAAwBuGEADAG4YQAMAbhhAAwBuGEADAG4YQAMAbhhAAwBuGEADAG4YQAMAbhhAAwJtJG9szNjbmHGuTkZHh3NcaDWKp7+7uNvUeGhpKWu9oNOpcO22a7d8i/f39SatPZmzPrFmzTL0t94t13a2traZ6SyRUTk6OqXd5eblzrTXiyVI/ODho6m2JBLLeJ9aYH0sElzX2KhQKmeotrI8JV5bHPFdCAABvGEIAAG8YQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvGEIAAG8YQgAAbxhCAABvGEIAAG8mbXZcenq6cy6YJVupr6/PtA5LhpQ1n8qSB9fb22vqbZGenm6qz8/PN9VbMvI6OztNvS2ZXdbcwMLCQuda695bz8MgCJxrrVljlgw2S1afJDU3NzvXWnPpLPehJUtRksrKykz1FsnMmJwxw/aUnpeX51ybmZnpXGvJUuRKCADgjWkI7dixQ3fddZdyc3OVm5urJUuW6E9/+lPi+0EQqKamRqWlpcrMzNSyZct0/PjxCV80ACA1mIZQWVmZXnrpJR0+fFiHDx/W8uXL9cgjjyQGzcsvv6ytW7dq+/btOnTokGKxmFasWKGenp6kLB4AMLWZhtDKlSv1ve99T/PmzdO8efP0L//yL8rJydHBgwcVBIG2bdumF154QatWrdL8+fO1a9cu9ff3a/fu3claPwBgCrvm3wmNjo5qz5496uvr05IlS9TQ0KDm5mZVVVUlasLhsB588EEdOHDgsn3i8bi6u7vH3QAANwfzEDp27JhycnIUDof11FNP6a233tIdd9yReBVMcXHxuPri4uIrvkKmtrZW0Wg0cbN8yiMAYGozD6HbbrtNR48e1cGDB/X0009rzZo1+vTTTxPfv/DloUEQXPElo5s3b1ZXV1fi1tjYaF0SAGCKMr9PKD09XbfeeqskadGiRTp06JB++ctf6he/+IWkr98XUFJSkqhvaWm56Orob4XDYfN7DwAAqeG63ycUBIHi8bgqKysVi8VUV1eX+N7Q0JDq6+u1dOnS6/1rAAApyHQl9Pzzz6u6ulrl5eXq6enRnj17tG/fPr3//vsKhULauHGjtmzZorlz52ru3LnasmWLsrKy9MQTTyRr/QCAKcw0hL766iv9+Mc/VlNTk6LRqO666y69//77WrFihSTpueee08DAgNatW6eOjg4tXrxYH374oSKRiHlhQRCYokpcWWJerPXWyAxLjIx13dOnT3eutUbOWGNhpk1zv+Bub2839ba8B21kZMTU27I/1r0fHBw01VseC5bIFMkWx2KNv7Hsj/U+icfjzrXWvS8qKkraWgYGBky9LY9963NmsuLALMdoeuT85je/ueL3Q6GQampqVFNTY2kLALhJkR0HAPCGIQQA8IYhBADwhiEEAPCGIQQA8IYhBADwhiEEAPCGIQQA8IYhBADwxpyinWznYycssQ+WWms0iDWixsKyFkssiLV3enp60npLttiR/v5+U+9k7r2ltyXix9pbssWxWCOeLPtviYOSkrs/yVqHZH/cDw0NOddaI54s+2mNJ7I+3lydv79dzttQkIyAtutw5swZPtgOAFJAY2OjysrKrlgz6YbQ2NiYzp49q0gkMu5fI93d3SovL1djY6Nyc3M9rjC5OM7UcTMco8RxppqJOM4gCNTT06PS0tKrBhhPuh/HTZs27YqTMzc3N6VPgPM4ztRxMxyjxHGmmus9TtfEdV6YAADwhiEEAPBmygyhcDisF198UeFw2PdSkorjTB03wzFKHGequdHHOelemAAAuHlMmSshAEDqYQgBALxhCAEAvGEIAQC8mTJD6NVXX1VlZaUyMjJ0zz336C9/+YvvJU2ompoahUKhcbdYLOZ7Wddl//79WrlypUpLSxUKhfT222+P+34QBKqpqVFpaakyMzO1bNkyHT9+3M9ir8PVjnPt2rUX7e19993nZ7HXqLa2Vvfee68ikYiKior06KOP6vPPPx9Xkwr76XKcqbCfO3bs0F133ZV4Q+qSJUv0pz/9KfH9G7mXU2IIvfHGG9q4caNeeOEFffzxx/r2t7+t6upqnT592vfSJtSdd96ppqamxO3YsWO+l3Rd+vr6tHDhQm3fvv2S33/55Ze1detWbd++XYcOHVIsFtOKFSvU09Nzg1d6fa52nJL08MMPj9vb99577wau8PrV19dr/fr1OnjwoOrq6jQyMqKqqir19fUlalJhP12OU5r6+1lWVqaXXnpJhw8f1uHDh7V8+XI98sgjiUFzQ/cymAK+9a1vBU899dS4r/3d3/1d8I//+I+eVjTxXnzxxWDhwoW+l5E0koK33nor8eexsbEgFosFL730UuJrg4ODQTQaDf793//dwwonxoXHGQRBsGbNmuCRRx7xsp5kaWlpCSQF9fX1QRCk7n5eeJxBkJr7GQRBkJeXF/z617++4Xs56a+EhoaGdOTIEVVVVY37elVVlQ4cOOBpVclx4sQJlZaWqrKyUo899phOnjzpe0lJ09DQoObm5nH7Gg6H9eCDD6bcvkrSvn37VFRUpHnz5unJJ59US0uL7yVdl66uLklSfn6+pNTdzwuP87xU2s/R0VHt2bNHfX19WrJkyQ3fy0k/hM6dO6fR0VEVFxeP+3pxcbGam5s9rWriLV68WK+99po++OAD/epXv1Jzc7OWLl2qtrY230tLivN7l+r7KknV1dV6/fXXtXfvXr3yyis6dOiQli9fbv6MqMkiCAJt2rRJ999/v+bPny8pNffzUscppc5+Hjt2TDk5OQqHw3rqqaf01ltv6Y477rjheznpUrQv58IPmQqCIKkfOHejVVdXJ/57wYIFWrJkiebMmaNdu3Zp06ZNHleWXKm+r5K0evXqxH/Pnz9fixYtUkVFhd59912tWrXK48quzYYNG/TJJ5/or3/960XfS6X9vNxxpsp+3nbbbTp69Kg6Ozv1hz/8QWvWrFF9fX3i+zdqLyf9lVBBQYGmT59+0QRuaWm5aFKnkuzsbC1YsEAnTpzwvZSkOP/Kv5ttXyWppKREFRUVU3Jvn3nmGb3zzjv66KOPxn3kSqrt5+WO81Km6n6mp6fr1ltv1aJFi1RbW6uFCxfql7/85Q3fy0k/hNLT03XPPfeorq5u3Nfr6uq0dOlST6tKvng8rs8++0wlJSW+l5IUlZWVisVi4/Z1aGhI9fX1Kb2vktTW1qbGxsYptbdBEGjDhg168803tXfvXlVWVo77fqrs59WO81Km4n5eShAEisfjN34vJ/ylDkmwZ8+eIC0tLfjNb34TfPrpp8HGjRuD7Ozs4NSpU76XNmGeffbZYN++fcHJkyeDgwcPBt///veDSCQypY+xp6cn+Pjjj4OPP/44kBRs3bo1+Pjjj4Mvv/wyCIIgeOmll4JoNBq8+eabwbFjx4LHH388KCkpCbq7uz2v3OZKx9nT0xM8++yzwYEDB4KGhobgo48+CpYsWRLccsstU+o4n3766SAajQb79u0LmpqaErf+/v5ETSrs59WOM1X2c/PmzcH+/fuDhoaG4JNPPgmef/75YNq0acGHH34YBMGN3cspMYSCIAj+7d/+LaioqAjS09ODu+++e9xLJlPB6tWrg5KSkiAtLS0oLS0NVq1aFRw/ftz3sq7LRx99FEi66LZmzZogCL5+We+LL74YxGKxIBwOBw888EBw7Ngxv4u+Blc6zv7+/qCqqiooLCwM0tLSgtmzZwdr1qwJTp8+7XvZJpc6PknBzp07EzWpsJ9XO85U2c9/+Id/SDyfFhYWBt/5zncSAygIbuxe8lEOAABvJv3vhAAAqYshBADwhiEEAPCGIQQA8IYhBADwhiEEAPCGIQQA8IYhBADwhiEEAPCGIQQA8IYhBADwhiEEAPDm/wAevKAfOd745gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0, 0].detach(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 16, 16])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(2)\n",
    "output = pool(img.unsqueeze(0))\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, kernel_size=3, padding=1),  # Layer 1\n",
    "    nn.Tanh(),  # Activation 1\n",
    "    nn.MaxPool2d(2),  # Pooling 1\n",
    "    nn.Conv2d(16, 8, kernel_size=3, padding=1),  # Layer 2\n",
    "    nn.Tanh(),  # Activation 2\n",
    "    nn.MaxPool2d(2),  # Pooling 2\n",
    "    nn.Flatten(),  # Flatten layer (Added)\n",
    "    nn.Linear(512, 32),  # Fully Connected Layer 1\n",
    "    nn.Tanh(),  # Activation 4\n",
    "    nn.Linear(32, 2),  # Fully Connected Layer 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18090"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1522,  0.1896]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = self.act3(self.fc1(out))\n",
    "        return self.fc2(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18090"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "\n",
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.625103\n",
      "Epoch: 1, Loss: 0.330666\n",
      "Epoch: 2, Loss: 0.463030\n",
      "Epoch: 3, Loss: 0.459484\n",
      "Epoch: 4, Loss: 0.249857\n",
      "Epoch: 5, Loss: 0.481206\n",
      "Epoch: 6, Loss: 0.583047\n",
      "Epoch: 7, Loss: 0.610404\n",
      "Epoch: 8, Loss: 0.230814\n",
      "Epoch: 9, Loss: 0.419008\n",
      "Epoch: 10, Loss: 0.438193\n",
      "Epoch: 11, Loss: 0.193210\n",
      "Epoch: 12, Loss: 0.148880\n",
      "Epoch: 13, Loss: 0.158207\n",
      "Epoch: 14, Loss: 0.612842\n",
      "Epoch: 15, Loss: 0.449868\n",
      "Epoch: 16, Loss: 0.155404\n",
      "Epoch: 17, Loss: 0.242829\n",
      "Epoch: 18, Loss: 0.312775\n",
      "Epoch: 19, Loss: 0.170020\n",
      "Epoch: 20, Loss: 0.298276\n",
      "Epoch: 21, Loss: 0.466996\n",
      "Epoch: 22, Loss: 0.596681\n",
      "Epoch: 23, Loss: 0.296458\n",
      "Epoch: 24, Loss: 0.239476\n",
      "Epoch: 25, Loss: 0.586413\n",
      "Epoch: 26, Loss: 0.222544\n",
      "Epoch: 27, Loss: 0.321402\n",
      "Epoch: 28, Loss: 0.237620\n",
      "Epoch: 29, Loss: 0.337007\n",
      "Epoch: 30, Loss: 0.580622\n",
      "Epoch: 31, Loss: 0.183228\n",
      "Epoch: 32, Loss: 0.519659\n",
      "Epoch: 33, Loss: 0.297368\n",
      "Epoch: 34, Loss: 0.140327\n",
      "Epoch: 35, Loss: 0.191947\n",
      "Epoch: 36, Loss: 0.114817\n",
      "Epoch: 37, Loss: 0.225188\n",
      "Epoch: 38, Loss: 0.308202\n",
      "Epoch: 39, Loss: 0.290237\n",
      "Epoch: 40, Loss: 0.194031\n",
      "Epoch: 41, Loss: 0.174405\n",
      "Epoch: 42, Loss: 0.162445\n",
      "Epoch: 43, Loss: 0.104549\n",
      "Epoch: 44, Loss: 0.169545\n",
      "Epoch: 45, Loss: 0.236851\n",
      "Epoch: 46, Loss: 0.395605\n",
      "Epoch: 47, Loss: 0.334036\n",
      "Epoch: 48, Loss: 0.069040\n",
      "Epoch: 49, Loss: 0.169866\n",
      "Epoch: 50, Loss: 0.198189\n",
      "Epoch: 51, Loss: 0.209108\n",
      "Epoch: 52, Loss: 0.195590\n",
      "Epoch: 53, Loss: 0.284586\n",
      "Epoch: 54, Loss: 0.083440\n",
      "Epoch: 55, Loss: 0.238287\n",
      "Epoch: 56, Loss: 0.146617\n",
      "Epoch: 57, Loss: 0.119984\n",
      "Epoch: 58, Loss: 0.365972\n",
      "Epoch: 59, Loss: 0.323034\n",
      "Epoch: 60, Loss: 0.042677\n",
      "Epoch: 61, Loss: 0.033257\n",
      "Epoch: 62, Loss: 0.123175\n",
      "Epoch: 63, Loss: 0.335444\n",
      "Epoch: 64, Loss: 0.686285\n",
      "Epoch: 65, Loss: 0.258339\n",
      "Epoch: 66, Loss: 0.170238\n",
      "Epoch: 67, Loss: 0.343524\n",
      "Epoch: 68, Loss: 0.120620\n",
      "Epoch: 69, Loss: 0.405735\n",
      "Epoch: 70, Loss: 0.194702\n",
      "Epoch: 71, Loss: 0.025869\n",
      "Epoch: 72, Loss: 0.133609\n",
      "Epoch: 73, Loss: 0.385789\n",
      "Epoch: 74, Loss: 0.259362\n",
      "Epoch: 75, Loss: 0.069071\n",
      "Epoch: 76, Loss: 0.146945\n",
      "Epoch: 77, Loss: 0.245516\n",
      "Epoch: 78, Loss: 0.069176\n",
      "Epoch: 79, Loss: 0.086193\n",
      "Epoch: 80, Loss: 0.299738\n",
      "Epoch: 81, Loss: 0.211782\n",
      "Epoch: 82, Loss: 0.241928\n",
      "Epoch: 83, Loss: 0.161687\n",
      "Epoch: 84, Loss: 0.149966\n",
      "Epoch: 85, Loss: 0.112021\n",
      "Epoch: 86, Loss: 0.242712\n",
      "Epoch: 87, Loss: 0.029105\n",
      "Epoch: 88, Loss: 0.124299\n",
      "Epoch: 89, Loss: 0.055005\n",
      "Epoch: 90, Loss: 0.112005\n",
      "Epoch: 91, Loss: 0.062014\n",
      "Epoch: 92, Loss: 0.057661\n",
      "Epoch: 93, Loss: 0.159956\n",
      "Epoch: 94, Loss: 0.137903\n",
      "Epoch: 95, Loss: 0.112873\n",
      "Epoch: 96, Loss: 0.066175\n",
      "Epoch: 97, Loss: 0.077461\n",
      "Epoch: 98, Loss: 0.043830\n",
      "Epoch: 99, Loss: 0.096714\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Net, self).__init__(*args, **kwargs)\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = Net()\n",
    "learning = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.952800\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 1 \n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "print(\"Accuracy : %.f \" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18090"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = Net()\n",
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0058,  0.1444]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(8 * 8 * 8, 32),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(32, 2),\n",
    ")\n",
    "\n",
    "model(img.unsqueeze(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
