{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7b2178ec2270>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class_names = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "data_path = \"../lesson3/dataset\"\n",
    "# cifar10 = datasets.CIFAR10(data_path, train=True, download=True)\n",
    "# cifar10 = datasets.CIFAR10(data_path, train=False, download=True)\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616)),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616)),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = [\"airplane\", \"bird\"]\n",
    "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_out = 2\n",
    "model = nn.Sequential(nn.Linear(3072, 512), nn.Tanh(), nn.Linear(512, n_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0900, 0.2447, 0.6652])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "x = torch.tensor([[1.0, 2.0, 3.0], [3.0, 4.0, 5.0]])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_out = 2\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512), nn.Tanh(), nn.Linear(512, n_out), nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7b206a2cac50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img.view(-1): Flattens the tensor.\n",
    "unsqueeze(0): Adds a batch dimension (resulting in a shape like [1, N], where N is the total number of elements in the original tensor).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3072])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch = img.view(-1).unsqueeze(0)\n",
    "img_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch2 = img.unsqueeze(0)\n",
    "img_batch2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (96x32 and 3072x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model(img)\n",
      "File \u001b[0;32m~/Software/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Software/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Software/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Software/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Software/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Software/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (96x32 and 3072x512)"
     ]
    }
   ],
   "source": [
    "model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4784, 0.5216]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(img_batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, index = torch.max(out, dim=1)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.tensor(\n",
    "    [\n",
    "        [0.6, 0.4],\n",
    "        [0.9, 0.1],\n",
    "        [0.3, 0.7],\n",
    "        [0.2, 0.8],\n",
    "    ]\n",
    ")\n",
    "\n",
    "class_index = torch.tensor([0, 0, 1, 1]).unsqueeze(1)\n",
    "class_index\n",
    "truth = torch.zeros((4, 2))\n",
    "truth\n",
    "truth.scatter_(dim=1, index=class_index, value=1.0)\n",
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1600, 0.1600],\n",
      "        [0.0100, 0.0100],\n",
      "        [0.0900, 0.0900],\n",
      "        [0.0400, 0.0400]])\n"
     ]
    }
   ],
   "source": [
    "def mse(out):\n",
    "    return ((out - truth) ** 2).sum(dim=1).mean()\n",
    "    # y = (out - truth) ** 2\n",
    "    # print(y)\n",
    "\n",
    "\n",
    "mse(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6000],\n",
       "        [0.9000],\n",
       "        [0.7000],\n",
       "        [0.8000]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.gather(dim=1, index=class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3024])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def likelihood(out):\n",
    "    prod = 1.0\n",
    "    for x in out.gather(dim=1, index=class_index):\n",
    "\n",
    "        prod *= x\n",
    "\n",
    "    return prod\n",
    "\n",
    "\n",
    "likelihood(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6000])\n",
      "tensor([0.6000])\n",
      "tensor([0.9000])\n",
      "tensor([0.5400])\n",
      "tensor([0.7000])\n",
      "tensor([0.3780])\n",
      "tensor([0.8000])\n",
      "tensor([0.3024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.1960])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def neg_log_likelihood(out):\n",
    "    return -likelihood(out).log()\n",
    "\n",
    "\n",
    "neg_log_likelihood(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6000, 0.4000],\n",
       "        [0.9000, 0.1000],\n",
       "        [0.3000, 0.7000],\n",
       "        [0.2000, 0.8000]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0750, 0.1500, 0.2500, 0.4750]),\n",
       " tensor([[0.9000, 0.1000],\n",
       "         [0.9000, 0.1000],\n",
       "         [0.3000, 0.7000],\n",
       "         [0.2000, 0.8000]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out0 = out.clone().detach()\n",
    "out0[0] = torch.tensor([0.9, 0.1])\n",
    "out2 = out.clone().detach()\n",
    "out2[0] = torch.tensor([0.4, 0.6])\n",
    "out3 = out.clone().detach()\n",
    "out3[0] = torch.tensor([0.1, 0.9])\n",
    "\n",
    "mse_comparison = torch.tensor([mse(o) for o in [out0, out, out2, out3]])\n",
    "mse_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9000, 0.1000],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.3000, 0.7000],\n",
      "        [0.2000, 0.8000]])\n",
      "tensor(0.0750)\n",
      "tensor([[0.6000, 0.4000],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.3000, 0.7000],\n",
      "        [0.2000, 0.8000]])\n",
      "tensor(0.1500)\n",
      "tensor([[0.4000, 0.6000],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.3000, 0.7000],\n",
      "        [0.2000, 0.8000]])\n",
      "tensor(0.2500)\n",
      "tensor([[0.1000, 0.9000],\n",
      "        [0.9000, 0.1000],\n",
      "        [0.3000, 0.7000],\n",
      "        [0.2000, 0.8000]])\n",
      "tensor(0.4750)\n"
     ]
    }
   ],
   "source": [
    "for o in [out0, out, out2, out3]:\n",
    "    print(o)\n",
    "    mse(o)\n",
    "    print(mse(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-50.0000,   0.0000,  66.6667, 216.6667])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((mse_comparison / mse_comparison[1]) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7905, 1.1960, 1.6015, 2.9878])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll_comparison = torch.tensor([neg_log_likelihood(o) for o in [out0, out, out2, out3]])\n",
    "nll_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-33.9016,   0.0000,  33.9016, 149.8121])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((nll_comparison / nll_comparison[1]) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[0.0, 104.0]])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-104.,    0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[0.0, 104.0]])\n",
    "\n",
    "log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, 0.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(log_softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5077, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 512), nn.Tanh(), nn.Linear(512, 2), nn.LogSoftmax(dim=1)\n",
    ")\n",
    "loss = nn.NLLLoss()\n",
    "img, label = cifar2[0]\n",
    "\n",
    "out = model(img.view(-1).unsqueeze(0))\n",
    "\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, LOss : 4.445263\n",
      "Epoch : 1, LOss : 4.367403\n",
      "Epoch : 2, LOss : 5.481987\n",
      "Epoch : 3, LOss : 3.168825\n",
      "Epoch : 4, LOss : 12.617499\n",
      "Epoch : 5, LOss : 6.689180\n",
      "Epoch : 6, LOss : 9.722066\n",
      "Epoch : 7, LOss : 4.721662\n",
      "Epoch : 8, LOss : 5.171774\n",
      "Epoch : 9, LOss : 10.724582\n",
      "Epoch : 10, LOss : 7.508717\n",
      "Epoch : 11, LOss : 6.297767\n",
      "Epoch : 12, LOss : 8.868284\n",
      "Epoch : 13, LOss : 13.856395\n",
      "Epoch : 14, LOss : 10.373698\n",
      "Epoch : 15, LOss : 9.347772\n",
      "Epoch : 16, LOss : 8.073361\n",
      "Epoch : 17, LOss : 0.508486\n",
      "Epoch : 18, LOss : 6.389364\n",
      "Epoch : 19, LOss : 0.365493\n",
      "Epoch : 20, LOss : 4.525823\n",
      "Epoch : 21, LOss : 5.434015\n",
      "Epoch : 22, LOss : 0.480586\n",
      "Epoch : 23, LOss : 2.973242\n",
      "Epoch : 24, LOss : 11.725420\n",
      "Epoch : 25, LOss : 0.180209\n",
      "Epoch : 26, LOss : 0.093298\n",
      "Epoch : 27, LOss : 0.973789\n",
      "Epoch : 28, LOss : 5.838484\n",
      "Epoch : 29, LOss : 14.743950\n",
      "Epoch : 30, LOss : 9.641453\n",
      "Epoch : 31, LOss : 6.851185\n",
      "Epoch : 32, LOss : 5.883249\n",
      "Epoch : 33, LOss : 8.782618\n",
      "Epoch : 34, LOss : 0.629203\n",
      "Epoch : 35, LOss : 14.061454\n",
      "Epoch : 36, LOss : 0.198170\n",
      "Epoch : 37, LOss : 7.132863\n",
      "Epoch : 38, LOss : 0.012378\n",
      "Epoch : 39, LOss : 0.218214\n",
      "Epoch : 40, LOss : 0.231969\n",
      "Epoch : 41, LOss : 9.951864\n",
      "Epoch : 42, LOss : 17.857370\n",
      "Epoch : 43, LOss : 9.943379\n",
      "Epoch : 44, LOss : 4.038421\n",
      "Epoch : 45, LOss : 9.458225\n",
      "Epoch : 46, LOss : 6.250255\n",
      "Epoch : 47, LOss : 1.439911\n",
      "Epoch : 48, LOss : 3.262594\n",
      "Epoch : 49, LOss : 7.605471\n",
      "Epoch : 50, LOss : 7.550667\n",
      "Epoch : 51, LOss : 19.254242\n",
      "Epoch : 52, LOss : 3.927224\n",
      "Epoch : 53, LOss : 8.951870\n",
      "Epoch : 54, LOss : 0.435055\n",
      "Epoch : 55, LOss : 13.627141\n",
      "Epoch : 56, LOss : 2.191931\n",
      "Epoch : 57, LOss : 8.286509\n",
      "Epoch : 58, LOss : 14.744528\n",
      "Epoch : 59, LOss : 28.310184\n",
      "Epoch : 60, LOss : 15.664705\n",
      "Epoch : 61, LOss : 13.938500\n",
      "Epoch : 62, LOss : 20.562969\n",
      "Epoch : 63, LOss : 20.770266\n",
      "Epoch : 64, LOss : 4.947156\n",
      "Epoch : 65, LOss : 24.358101\n",
      "Epoch : 66, LOss : 16.340145\n",
      "Epoch : 67, LOss : 6.799802\n",
      "Epoch : 68, LOss : 11.785608\n",
      "Epoch : 69, LOss : 8.573864\n",
      "Epoch : 70, LOss : 6.991143\n",
      "Epoch : 71, LOss : 5.376113\n",
      "Epoch : 72, LOss : 0.017815\n",
      "Epoch : 73, LOss : 5.916370\n",
      "Epoch : 74, LOss : 11.741486\n",
      "Epoch : 75, LOss : 5.130210\n",
      "Epoch : 76, LOss : 7.785915\n",
      "Epoch : 77, LOss : 4.916218\n",
      "Epoch : 78, LOss : 15.459206\n",
      "Epoch : 79, LOss : 10.885416\n",
      "Epoch : 80, LOss : 14.512176\n",
      "Epoch : 81, LOss : 4.318145\n",
      "Epoch : 82, LOss : 9.437535\n",
      "Epoch : 83, LOss : 15.236090\n",
      "Epoch : 84, LOss : 10.208467\n",
      "Epoch : 85, LOss : 15.634747\n",
      "Epoch : 86, LOss : 13.855781\n",
      "Epoch : 87, LOss : 13.649228\n",
      "Epoch : 88, LOss : 1.520911\n",
      "Epoch : 89, LOss : 11.224800\n",
      "Epoch : 90, LOss : 7.865527\n",
      "Epoch : 91, LOss : 12.317416\n",
      "Epoch : 92, LOss : 0.433134\n",
      "Epoch : 93, LOss : 9.423051\n",
      "Epoch : 94, LOss : 6.532728\n",
      "Epoch : 95, LOss : 17.757982\n",
      "Epoch : 96, LOss : 12.968786\n",
      "Epoch : 97, LOss : 15.837273\n",
      "Epoch : 98, LOss : 16.208290\n",
      "Epoch : 99, LOss : 6.942454\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "mdoel = nn.Sequential(\n",
    "    nn.Linear(3072, 512), nn.Tanh(), nn.Linear(512, 2), nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in cifar2:\n",
    "        out = model(img.view(-1).unsqueeze(0))\n",
    "        loss = loss_fn(out, torch.tensor([label]))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch : %d, LOss : %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Loss : 0.993731\n",
      "Epoch : 1, Loss : 0.653510\n",
      "Epoch : 2, Loss : 0.037373\n",
      "Epoch : 3, Loss : 0.072298\n",
      "Epoch : 4, Loss : 0.365193\n",
      "Epoch : 5, Loss : 0.371821\n",
      "Epoch : 6, Loss : 0.030141\n",
      "Epoch : 7, Loss : 0.048294\n",
      "Epoch : 8, Loss : 0.069407\n",
      "Epoch : 9, Loss : 0.066418\n",
      "Epoch : 10, Loss : 0.292597\n",
      "Epoch : 11, Loss : 0.457423\n",
      "Epoch : 12, Loss : 0.010392\n",
      "Epoch : 13, Loss : 0.327289\n",
      "Epoch : 14, Loss : 0.087291\n",
      "Epoch : 15, Loss : 0.025777\n",
      "Epoch : 16, Loss : 0.005806\n",
      "Epoch : 17, Loss : 0.061225\n",
      "Epoch : 18, Loss : 0.055023\n",
      "Epoch : 19, Loss : 0.045844\n",
      "Epoch : 20, Loss : 0.124459\n",
      "Epoch : 21, Loss : 0.443585\n",
      "Epoch : 22, Loss : 0.482496\n",
      "Epoch : 23, Loss : 0.006191\n",
      "Epoch : 24, Loss : 0.091066\n",
      "Epoch : 25, Loss : 0.044534\n",
      "Epoch : 26, Loss : 0.377320\n",
      "Epoch : 27, Loss : 0.088943\n",
      "Epoch : 28, Loss : 0.036286\n",
      "Epoch : 29, Loss : 0.108661\n",
      "Epoch : 30, Loss : 0.244442\n",
      "Epoch : 31, Loss : 0.152405\n",
      "Epoch : 32, Loss : 0.108267\n",
      "Epoch : 33, Loss : 0.215112\n",
      "Epoch : 34, Loss : 0.189628\n",
      "Epoch : 35, Loss : 0.748387\n",
      "Epoch : 36, Loss : 0.278267\n",
      "Epoch : 37, Loss : 0.138966\n",
      "Epoch : 38, Loss : 0.390748\n",
      "Epoch : 39, Loss : 0.306050\n",
      "Epoch : 40, Loss : 0.107929\n",
      "Epoch : 41, Loss : 0.148373\n",
      "Epoch : 42, Loss : 0.512275\n",
      "Epoch : 43, Loss : 0.140038\n",
      "Epoch : 44, Loss : 0.065503\n",
      "Epoch : 45, Loss : 0.347469\n",
      "Epoch : 46, Loss : 0.334116\n",
      "Epoch : 47, Loss : 0.046449\n",
      "Epoch : 48, Loss : 0.155710\n",
      "Epoch : 49, Loss : 0.102873\n",
      "Epoch : 50, Loss : 0.033677\n",
      "Epoch : 51, Loss : 0.065841\n",
      "Epoch : 52, Loss : 0.135423\n",
      "Epoch : 53, Loss : 0.245842\n",
      "Epoch : 54, Loss : 0.147839\n",
      "Epoch : 55, Loss : 0.442246\n",
      "Epoch : 56, Loss : 0.295239\n",
      "Epoch : 57, Loss : 0.118035\n",
      "Epoch : 58, Loss : 0.048258\n",
      "Epoch : 59, Loss : 0.274756\n",
      "Epoch : 60, Loss : 0.112533\n",
      "Epoch : 61, Loss : 0.102915\n",
      "Epoch : 62, Loss : 0.065207\n",
      "Epoch : 63, Loss : 0.063314\n",
      "Epoch : 64, Loss : 0.016677\n",
      "Epoch : 65, Loss : 0.459163\n",
      "Epoch : 66, Loss : 0.154705\n",
      "Epoch : 67, Loss : 0.129688\n",
      "Epoch : 68, Loss : 0.040098\n",
      "Epoch : 69, Loss : 0.361300\n",
      "Epoch : 70, Loss : 0.136286\n",
      "Epoch : 71, Loss : 0.073101\n",
      "Epoch : 72, Loss : 0.103262\n",
      "Epoch : 73, Loss : 0.347947\n",
      "Epoch : 74, Loss : 0.178439\n",
      "Epoch : 75, Loss : 0.036153\n",
      "Epoch : 76, Loss : 0.289163\n",
      "Epoch : 77, Loss : 0.104216\n",
      "Epoch : 78, Loss : 0.176688\n",
      "Epoch : 79, Loss : 0.196379\n",
      "Epoch : 80, Loss : 0.477589\n",
      "Epoch : 81, Loss : 0.104072\n",
      "Epoch : 82, Loss : 0.429058\n",
      "Epoch : 83, Loss : 0.333608\n",
      "Epoch : 84, Loss : 0.192339\n",
      "Epoch : 85, Loss : 0.027906\n",
      "Epoch : 86, Loss : 0.028151\n",
      "Epoch : 87, Loss : 0.052103\n",
      "Epoch : 88, Loss : 0.196310\n",
      "Epoch : 89, Loss : 0.057100\n",
      "Epoch : 90, Loss : 0.097350\n",
      "Epoch : 91, Loss : 0.052536\n",
      "Epoch : 92, Loss : 0.121333\n",
      "Epoch : 93, Loss : 0.467725\n",
      "Epoch : 94, Loss : 0.055603\n",
      "Epoch : 95, Loss : 0.047926\n",
      "Epoch : 96, Loss : 0.455349\n",
      "Epoch : 97, Loss : 0.389078\n",
      "Epoch : 98, Loss : 0.286142\n",
      "Epoch : 99, Loss : 0.151918\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "mdoel = nn.Sequential(\n",
    "    nn.Linear(3072, 128), nn.Tanh(), nn.Linear(128, 2), nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in train_loader:\n",
    "        out = model(img.view(img.shape[0], -1))\n",
    "        loss = loss_fn(out, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch : %d, Loss : %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Loss : 0.174268\n",
      "Epoch : 1, Loss : 0.136959\n",
      "Epoch : 2, Loss : 0.004313\n",
      "Epoch : 3, Loss : 0.326512\n",
      "Epoch : 4, Loss : 0.421827\n",
      "Epoch : 5, Loss : 0.150288\n",
      "Epoch : 6, Loss : 0.022458\n",
      "Epoch : 7, Loss : 0.241371\n",
      "Epoch : 8, Loss : 0.092438\n",
      "Epoch : 9, Loss : 0.191329\n",
      "Epoch : 10, Loss : 0.147624\n",
      "Epoch : 11, Loss : 0.017155\n",
      "Epoch : 12, Loss : 0.005376\n",
      "Epoch : 13, Loss : 0.009239\n",
      "Epoch : 14, Loss : 0.019962\n",
      "Epoch : 15, Loss : 0.195628\n",
      "Epoch : 16, Loss : 0.028694\n",
      "Epoch : 17, Loss : 0.015584\n",
      "Epoch : 18, Loss : 0.148816\n",
      "Epoch : 19, Loss : 0.108175\n",
      "Epoch : 20, Loss : 0.137405\n",
      "Epoch : 21, Loss : 0.082982\n",
      "Epoch : 22, Loss : 0.024785\n",
      "Epoch : 23, Loss : 0.122263\n",
      "Epoch : 24, Loss : 0.092117\n",
      "Epoch : 25, Loss : 0.149515\n",
      "Epoch : 26, Loss : 0.187000\n",
      "Epoch : 27, Loss : 0.189935\n",
      "Epoch : 28, Loss : 0.026156\n",
      "Epoch : 29, Loss : 0.064289\n",
      "Epoch : 30, Loss : 0.059273\n",
      "Epoch : 31, Loss : 0.443261\n",
      "Epoch : 32, Loss : 0.002924\n",
      "Epoch : 33, Loss : 0.016522\n",
      "Epoch : 34, Loss : 0.168449\n",
      "Epoch : 35, Loss : 0.270583\n",
      "Epoch : 36, Loss : 0.007776\n",
      "Epoch : 37, Loss : 0.029969\n",
      "Epoch : 38, Loss : 0.003870\n",
      "Epoch : 39, Loss : 0.019324\n",
      "Epoch : 40, Loss : 0.069936\n",
      "Epoch : 41, Loss : 0.242294\n",
      "Epoch : 42, Loss : 0.020883\n",
      "Epoch : 43, Loss : 0.118739\n",
      "Epoch : 44, Loss : 0.019163\n",
      "Epoch : 45, Loss : 0.100989\n",
      "Epoch : 46, Loss : 0.025654\n",
      "Epoch : 47, Loss : 0.010419\n",
      "Epoch : 48, Loss : 0.027514\n",
      "Epoch : 49, Loss : 0.590619\n",
      "Epoch : 50, Loss : 0.111046\n",
      "Epoch : 51, Loss : 0.100433\n",
      "Epoch : 52, Loss : 0.052646\n",
      "Epoch : 53, Loss : 0.113176\n",
      "Epoch : 54, Loss : 0.088899\n",
      "Epoch : 55, Loss : 0.111827\n",
      "Epoch : 56, Loss : 0.069436\n",
      "Epoch : 57, Loss : 0.062519\n",
      "Epoch : 58, Loss : 0.111696\n",
      "Epoch : 59, Loss : 0.044563\n",
      "Epoch : 60, Loss : 0.077963\n",
      "Epoch : 61, Loss : 0.050021\n",
      "Epoch : 62, Loss : 0.006339\n",
      "Epoch : 63, Loss : 0.459719\n",
      "Epoch : 64, Loss : 0.044307\n",
      "Epoch : 65, Loss : 0.098067\n",
      "Epoch : 66, Loss : 0.029235\n",
      "Epoch : 67, Loss : 0.023011\n",
      "Epoch : 68, Loss : 0.145502\n",
      "Epoch : 69, Loss : 0.108779\n",
      "Epoch : 70, Loss : 0.131590\n",
      "Epoch : 71, Loss : 0.222882\n",
      "Epoch : 72, Loss : 0.328742\n",
      "Epoch : 73, Loss : 0.004835\n",
      "Epoch : 74, Loss : 0.158386\n",
      "Epoch : 75, Loss : 0.159201\n",
      "Epoch : 76, Loss : 0.124717\n",
      "Epoch : 77, Loss : 0.250470\n",
      "Epoch : 78, Loss : 0.007872\n",
      "Epoch : 79, Loss : 0.058336\n",
      "Epoch : 80, Loss : 0.048865\n",
      "Epoch : 81, Loss : 0.031155\n",
      "Epoch : 82, Loss : 0.078045\n",
      "Epoch : 83, Loss : 0.024809\n",
      "Epoch : 84, Loss : 0.017487\n",
      "Epoch : 85, Loss : 0.085442\n",
      "Epoch : 86, Loss : 0.077494\n",
      "Epoch : 87, Loss : 0.006137\n",
      "Epoch : 88, Loss : 0.041011\n",
      "Epoch : 89, Loss : 0.295973\n",
      "Epoch : 90, Loss : 0.077105\n",
      "Epoch : 91, Loss : 0.029906\n",
      "Epoch : 92, Loss : 0.525899\n",
      "Epoch : 93, Loss : 0.139337\n",
      "Epoch : 94, Loss : 0.019295\n",
      "Epoch : 95, Loss : 0.035565\n",
      "Epoch : 96, Loss : 0.044276\n",
      "Epoch : 97, Loss : 0.010894\n",
      "Epoch : 98, Loss : 0.123948\n",
      "Epoch : 99, Loss : 0.052417\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "mdoel = nn.Sequential(\n",
    "    nn.Linear(3072, 512), nn.Tanh(), nn.Linear(512, 2), nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.NLLLoss()\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in train_loader:\n",
    "        out = model(img.view(img.shape[0], -1))\n",
    "        loss = loss_fn(out, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch : %d, Loss : %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 tensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "128 tensor([0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0])\n",
      "192 tensor([1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0])\n",
      "256 tensor([1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0])\n",
      "320 tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0])\n",
      "384 tensor([0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1])\n",
      "448 tensor([0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1])\n",
      "512 tensor([0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0])\n",
      "576 tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0])\n",
      "640 tensor([1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0])\n",
      "704 tensor([0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1])\n",
      "768 tensor([1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0])\n",
      "832 tensor([0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0])\n",
      "896 tensor([1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1])\n",
      "960 tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])\n",
      "1024 tensor([0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "1088 tensor([0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1])\n",
      "1152 tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0])\n",
      "1216 tensor([0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0])\n",
      "1280 tensor([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1])\n",
      "1344 tensor([1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])\n",
      "1408 tensor([1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1])\n",
      "1472 tensor([0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1])\n",
      "1536 tensor([1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1])\n",
      "1600 tensor([0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1])\n",
      "1664 tensor([1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1])\n",
      "1728 tensor([1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1])\n",
      "1792 tensor([0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0])\n",
      "1856 tensor([0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1])\n",
      "1920 tensor([1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1])\n",
      "1984 tensor([1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1])\n",
      "2048 tensor([1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0])\n",
      "2112 tensor([0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1])\n",
      "2176 tensor([1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0])\n",
      "2240 tensor([1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0])\n",
      "2304 tensor([0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0])\n",
      "2368 tensor([1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1])\n",
      "2432 tensor([0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1])\n",
      "2496 tensor([0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0])\n",
      "2560 tensor([0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "2624 tensor([1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0])\n",
      "2688 tensor([1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0])\n",
      "2752 tensor([1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0])\n",
      "2816 tensor([1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1])\n",
      "2880 tensor([0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1])\n",
      "2944 tensor([1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0])\n",
      "3008 tensor([1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0])\n",
      "3072 tensor([0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1])\n",
      "3136 tensor([1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1])\n",
      "3200 tensor([0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1])\n",
      "3264 tensor([0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0])\n",
      "3328 tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1])\n",
      "3392 tensor([1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1])\n",
      "3456 tensor([0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1])\n",
      "3520 tensor([1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1])\n",
      "3584 tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1])\n",
      "3648 tensor([1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "3712 tensor([1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1])\n",
      "3776 tensor([0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "3840 tensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0])\n",
      "3904 tensor([0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0])\n",
      "3968 tensor([0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1])\n",
      "4032 tensor([1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0])\n",
      "4096 tensor([1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1])\n",
      "4160 tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1])\n",
      "4224 tensor([1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1])\n",
      "4288 tensor([0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0])\n",
      "4352 tensor([0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0])\n",
      "4416 tensor([1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1])\n",
      "4480 tensor([0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0])\n",
      "4544 tensor([0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1])\n",
      "4608 tensor([1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1])\n",
      "4672 tensor([0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0])\n",
      "4736 tensor([0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1])\n",
      "4800 tensor([1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n",
      "4864 tensor([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
      "4928 tensor([0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0])\n",
      "4992 tensor([1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1])\n",
      "5056 tensor([1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1])\n",
      "5120 tensor([0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0])\n",
      "5184 tensor([1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])\n",
      "5248 tensor([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1])\n",
      "5312 tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0])\n",
      "5376 tensor([0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1])\n",
      "5440 tensor([1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0])\n",
      "5504 tensor([1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
      "5568 tensor([1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0])\n",
      "5632 tensor([1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1])\n",
      "5696 tensor([0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0])\n",
      "5760 tensor([1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0])\n",
      "5824 tensor([1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1])\n",
      "5888 tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0])\n",
      "5952 tensor([0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1])\n",
      "6016 tensor([1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1])\n",
      "6080 tensor([0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0])\n",
      "6144 tensor([0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1])\n",
      "6208 tensor([1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0])\n",
      "6272 tensor([1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1])\n",
      "6336 tensor([1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0])\n",
      "6400 tensor([1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0])\n",
      "6464 tensor([1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0])\n",
      "6528 tensor([0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1])\n",
      "6592 tensor([1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1])\n",
      "6656 tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])\n",
      "6720 tensor([0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0])\n",
      "6784 tensor([1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0])\n",
      "6848 tensor([1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1])\n",
      "6912 tensor([0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1])\n",
      "6976 tensor([0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0])\n",
      "7040 tensor([1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0])\n",
      "7104 tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0])\n",
      "7168 tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1])\n",
      "7232 tensor([0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1])\n",
      "7296 tensor([1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1])\n",
      "7360 tensor([0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0])\n",
      "7424 tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0])\n",
      "7488 tensor([1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0])\n",
      "7552 tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1])\n",
      "7616 tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1])\n",
      "7680 tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
      "        1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0])\n",
      "7744 tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1])\n",
      "7808 tensor([1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1])\n",
      "7872 tensor([1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1])\n",
      "7936 tensor([0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0])\n",
      "8000 tensor([1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1])\n",
      "8064 tensor([1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0])\n",
      "8128 tensor([0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0])\n",
      "8192 tensor([0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0])\n",
      "8256 tensor([0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1])\n",
      "8320 tensor([0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1])\n",
      "8384 tensor([1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0])\n",
      "8448 tensor([0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0])\n",
      "8512 tensor([1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0])\n",
      "8576 tensor([0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0])\n",
      "8640 tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1])\n",
      "8704 tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1])\n",
      "8768 tensor([1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0])\n",
      "8832 tensor([0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0])\n",
      "8896 tensor([1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1])\n",
      "8960 tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1])\n",
      "9024 tensor([0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])\n",
      "9088 tensor([0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0])\n",
      "9152 tensor([0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0])\n",
      "9216 tensor([1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1])\n",
      "9280 tensor([1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
      "        0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1])\n",
      "9344 tensor([0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1])\n",
      "9408 tensor([0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0])\n",
      "9472 tensor([1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0])\n",
      "9536 tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "        1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1])\n",
      "9600 tensor([0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "        0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0])\n",
      "9664 tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0])\n",
      "9728 tensor([0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0])\n",
      "9792 tensor([1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1])\n",
      "9856 tensor([0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0])\n",
      "9920 tensor([0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
      "9984 tensor([0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1])\n",
      "10000 tensor([1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1])\n",
      "Accuracy: 0.962200\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        print(total, labels)\n",
    "        correct += int((predicted == labels).sum())\n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.748500\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "\n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.410539\n",
      "Epoch: 1, Loss: 0.607154\n",
      "Epoch: 2, Loss: 0.474970\n",
      "Epoch: 3, Loss: 0.485383\n",
      "Epoch: 4, Loss: 0.321286\n",
      "Epoch: 5, Loss: 0.182294\n",
      "Epoch: 6, Loss: 0.323795\n",
      "Epoch: 7, Loss: 0.327945\n",
      "Epoch: 8, Loss: 0.784662\n",
      "Epoch: 9, Loss: 0.255426\n",
      "Epoch: 10, Loss: 0.422364\n",
      "Epoch: 11, Loss: 0.667554\n",
      "Epoch: 12, Loss: 0.401560\n",
      "Epoch: 13, Loss: 0.549555\n",
      "Epoch: 14, Loss: 0.805928\n",
      "Epoch: 15, Loss: 0.282594\n",
      "Epoch: 16, Loss: 0.342534\n",
      "Epoch: 17, Loss: 0.150693\n",
      "Epoch: 18, Loss: 0.436469\n",
      "Epoch: 19, Loss: 0.286100\n",
      "Epoch: 20, Loss: 0.198358\n",
      "Epoch: 21, Loss: 0.454082\n",
      "Epoch: 22, Loss: 0.183760\n",
      "Epoch: 23, Loss: 0.126981\n",
      "Epoch: 24, Loss: 0.514936\n",
      "Epoch: 25, Loss: 0.259356\n",
      "Epoch: 26, Loss: 0.391230\n",
      "Epoch: 27, Loss: 0.294232\n",
      "Epoch: 28, Loss: 0.454814\n",
      "Epoch: 29, Loss: 0.257044\n",
      "Epoch: 30, Loss: 0.319317\n",
      "Epoch: 31, Loss: 0.169349\n",
      "Epoch: 32, Loss: 0.408393\n",
      "Epoch: 33, Loss: 0.151755\n",
      "Epoch: 34, Loss: 0.189955\n",
      "Epoch: 35, Loss: 0.102435\n",
      "Epoch: 36, Loss: 0.165404\n",
      "Epoch: 37, Loss: 0.469103\n",
      "Epoch: 38, Loss: 0.225008\n",
      "Epoch: 39, Loss: 0.128548\n",
      "Epoch: 40, Loss: 0.123879\n",
      "Epoch: 41, Loss: 0.076277\n",
      "Epoch: 42, Loss: 0.059380\n",
      "Epoch: 43, Loss: 0.041811\n",
      "Epoch: 44, Loss: 0.049377\n",
      "Epoch: 45, Loss: 0.034898\n",
      "Epoch: 46, Loss: 0.045547\n",
      "Epoch: 47, Loss: 0.183847\n",
      "Epoch: 48, Loss: 0.027860\n",
      "Epoch: 49, Loss: 0.019763\n",
      "Epoch: 50, Loss: 0.088968\n",
      "Epoch: 51, Loss: 0.003589\n",
      "Epoch: 52, Loss: 0.046232\n",
      "Epoch: 53, Loss: 0.021976\n",
      "Epoch: 54, Loss: 0.027044\n",
      "Epoch: 55, Loss: 0.063864\n",
      "Epoch: 56, Loss: 0.012447\n",
      "Epoch: 57, Loss: 0.018418\n",
      "Epoch: 58, Loss: 0.013075\n",
      "Epoch: 59, Loss: 0.051639\n",
      "Epoch: 60, Loss: 0.014300\n",
      "Epoch: 61, Loss: 0.012168\n",
      "Epoch: 62, Loss: 0.220876\n",
      "Epoch: 63, Loss: 0.010402\n",
      "Epoch: 64, Loss: 0.014320\n",
      "Epoch: 65, Loss: 0.002585\n",
      "Epoch: 66, Loss: 0.124088\n",
      "Epoch: 67, Loss: 0.007486\n",
      "Epoch: 68, Loss: 0.115336\n",
      "Epoch: 69, Loss: 0.011834\n",
      "Epoch: 70, Loss: 0.015266\n",
      "Epoch: 71, Loss: 0.018681\n",
      "Epoch: 72, Loss: 0.003886\n",
      "Epoch: 73, Loss: 0.005152\n",
      "Epoch: 74, Loss: 0.003023\n",
      "Epoch: 75, Loss: 0.003031\n",
      "Epoch: 76, Loss: 0.019633\n",
      "Epoch: 77, Loss: 0.002898\n",
      "Epoch: 78, Loss: 0.005386\n",
      "Epoch: 79, Loss: 0.008980\n",
      "Epoch: 80, Loss: 0.006238\n",
      "Epoch: 81, Loss: 0.005263\n",
      "Epoch: 82, Loss: 0.051174\n",
      "Epoch: 83, Loss: 0.011473\n",
      "Epoch: 84, Loss: 0.014332\n",
      "Epoch: 85, Loss: 0.000163\n",
      "Epoch: 86, Loss: 0.001442\n",
      "Epoch: 87, Loss: 0.004674\n",
      "Epoch: 88, Loss: 0.002694\n",
      "Epoch: 89, Loss: 0.013764\n",
      "Epoch: 90, Loss: 0.000839\n",
      "Epoch: 91, Loss: 0.001244\n",
      "Epoch: 92, Loss: 0.002450\n",
      "Epoch: 93, Loss: 0.001018\n",
      "Epoch: 94, Loss: 0.002898\n",
      "Epoch: 95, Loss: 0.001254\n",
      "Epoch: 96, Loss: 0.000617\n",
      "Epoch: 97, Loss: 0.001095\n",
      "Epoch: 98, Loss: 0.001425\n",
      "Epoch: 99, Loss: 0.001805\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 1024),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(128, 2),\n",
    ")\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "\n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.800500\n"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "\n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3737474"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3737474"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters() if p.requires_grad == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 3072]), torch.Size([1024]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(3072, 1024)\n",
    "linear.weight.shape, linear.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 3, 3])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3, 16, kernel_size=3)\n",
    "conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = cifar2[0]\n",
    "output = conv(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.6139, -0.3228,  ..., -0.2752, -0.5451],\n",
       "          [ 0.6615, -0.1482,  ..., -0.3228, -0.5768],\n",
       "          ...,\n",
       "          [ 0.5980,  0.4393,  ..., -0.4340,  0.0265],\n",
       "          [ 0.9156,  0.8044,  ..., -0.5451, -0.0529]],\n",
       "\n",
       "         [[ 1.3369,  0.2740,  ...,  0.3867,  0.0968],\n",
       "          [ 1.4497,  0.5961,  ...,  0.3062,  0.0646],\n",
       "          ...,\n",
       "          [ 0.5478,  0.6605,  ...,  0.4028,  0.8860],\n",
       "          [ 0.4834,  0.9504,  ...,  0.1613,  0.7572]],\n",
       "\n",
       "         [[-0.4487, -0.7935,  ..., -0.6736, -0.8535],\n",
       "          [-0.4487, -0.9734,  ..., -0.6286, -0.8535],\n",
       "          ...,\n",
       "          [-0.4337, -0.4787,  ..., -1.3032, -0.9884],\n",
       "          [-0.1789,  0.0310,  ..., -1.3182, -1.0484]]]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 32, 32]), torch.Size([1, 1, 32, 32]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.unsqueeze(0).shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.permute(1, 2, 0), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detach():\n",
    "This removes the tensor from the computational graph (used in PyTorch), meaning the tensor is no longer connected to the computation of gradients. This is necessary if output is the result of a forward pass in a neural network and you're only interested in displaying the image without computing further gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(output[0, 0].detach(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "output = conv(img.unsqueeze(0))\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    conv.weight.fill_(1.0 / 9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0, 0].detach(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(3, 1, kernel_size=3, padding=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    conv.weight[:] = torch.tensor(\n",
    "        [[-1.0, 0.0, 1.0], [-1.0, 0.0, 1.0], [-1.0, 0.0, 1.0]]\n",
    "    )\n",
    "    conv.bias.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = conv(img.unsqueeze(0))\n",
    "plt.imshow(output[0, 0].detach(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 16, 16])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(2)\n",
    "output = pool(img.unsqueeze(0))\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "    nn.Tanh(),\n",
    "    nn.MaxPool2d(2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, kernel_size=3, padding=1),  # Layer 1\n",
    "    nn.Tanh(),  # Activation 1\n",
    "    nn.MaxPool2d(2),  # Pooling 1\n",
    "    nn.Conv2d(16, 8, kernel_size=3, padding=1),  # Layer 2\n",
    "    nn.Tanh(),  # Activation 2\n",
    "    nn.MaxPool2d(2),  # Pooling 2\n",
    "    nn.Flatten(),  # Flatten layer (Added)\n",
    "    nn.Linear(512, 32),  # Fully Connected Layer 1\n",
    "    nn.Tanh(),  # Activation 4\n",
    "    nn.Linear(32, 2),  # Fully Connected Layer 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18090"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1153, -0.0079]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(img.unsqueeze(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
